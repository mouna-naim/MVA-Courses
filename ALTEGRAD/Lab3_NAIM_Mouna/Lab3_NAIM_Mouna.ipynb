{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsD-LMKT7XMt"
   },
   "source": [
    "<center>\n",
    "<h2> </h2>\n",
    "<h2>ALTeGraD 2024<br>\n",
    "<h2>Lab Session 3: Large Language Models</h2>\n",
    "<h5>October 22, 2024</h5>\n",
    "<h4><b>Student Name:</b> NAIM Mouna</h4> \n",
    "<br>\n",
    "</center>\n",
    "[Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B)\n",
    "<hr style=\"border:10px solid gray\"> </hr>\n",
    "<p style=\"text-align: justify;\">\n",
    "This handout includes theoretical introductions, <font color='blue'>coding tasks</font> and <font color='red'>questions</font>. Before the deadline, you should submit a <B>.ipynb</B> file named <b>Lastname_Firstname.ipynb</b> containing your notebook (with the gaps filled and your answers to the questions). Your answers should be well constructed and well justified. They should not repeat the question or generalities in the handout. When relevant, you are welcome to include figures, equations and tables derived from your own computations, theoretical proofs or qualitative explanations. One submission is required for each student. The deadline for this lab is <b>October 29, 2024 11:59 PM</b>. No extension will be granted. Late policy is as follows: ]0, 24] hours late → -5 pts; ]24, 48] hours late → -10 pts; > 48 hours late → not graded (zero).\n",
    "\n",
    "<hr style=\"border:5px solid gray\"> </hr>\n",
    "\n",
    "<hr style=\"border:5px solid gray\"> </hr>\n",
    "\n",
    "* Please submit your file to Moodle or [here](https://docs.google.com/forms/d/e/1FAIpQLSfDFjQcvjKxLn42Kxpw5ek2Ce_lHzMCVSST8R2AJcQct6Np2A/viewform)\n",
    "\n",
    "<br><br>\n",
    "In this lab, we will:\n",
    "\n",
    "* fintune [Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B) on a question/answer dataset.\n",
    "\n",
    "* To reduce the required GPU VRAM for the finetuning, we will use [LoRA](https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2) and [quantization](https://huggingface.co/blog/4bit-transformers-bitsandbytes) techniques.\n",
    "\n",
    "* Compare the results before and after instructin tuning.\n",
    "\n",
    "* Fintune the model again on perference dataset using [DPO](https://huggingface.co/docs/trl/main/dpo_trainer#dpo-trainer)(direct perference optimization)\n",
    " <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUCV4V0ONKeJ"
   },
   "source": [
    "# <b>Part 1 Finetuning Qwen2.5-0.5B using HuggingFace's Transfromers</b>\n",
    "In this section, we will fintune [Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B) on a question/answer dataset.\n",
    "\n",
    "To reduce the required GPU VRAM for the finetuning, we will use [LoRA](https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2) and [quantization](https://huggingface.co/blog/4bit-transformers-bitsandbytes) techniques.\n",
    "\n",
    "## <b>Preparing the environment and installing libraries:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvYPeqtmLTiu",
    "outputId": "a2559848-f337-42f3-a0ca-648ea93a375e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 27 14:10:11 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.33                 Driver Version: 546.33       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P0              17W /  75W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "khRdXTxqy9V_"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq bitsandbytes torch transformers peft accelerate datasets loralib einops trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wLhVbYWg9xX",
    "outputId": "00ae8ed2-a939-4664-de35-295b3f713dc3"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers==4.45.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qHHXf0xHUsx9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC-Kv8g8MSuW"
   },
   "source": [
    "## <b>Loading the model and the tokenizer:<b>\n",
    "\n",
    "In this section, we will load the QWEN model while using the BitsAndBytes library for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6TaXDnRVKDq",
    "outputId": "52bc111c-c77e-48f8-82a2-e976b30df3a2"
   },
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\n",
    "MODEL_NAME = \"unsloth/Llama-3.2-1B\" # Try Llama if you want\n",
    "\n",
    "# fill the gap (filled)\n",
    "# We will use the function \"BitsAndBytesConfig\" to configure quantization parameters \n",
    "# To reduce VRAM usage, we will use 4bit precision\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    #bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    #bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_use_double_quant=True\n",
    ") \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    #force_download=True,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LIvuxW4lVW_E"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        # fill the gap: get the number of trainable parameters: trainable_params\n",
    "        # We will check if the parameter is trainable\n",
    "        if param.requires_grad:  \n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTgKyxhJMeEP"
   },
   "source": [
    "## <b>Configuring LoRA:<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ3oqsuFUJ9v"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duTYSKKYVamH",
    "outputId": "1e6e34ed-bfb6-4efe-a5dc-210a99aa77ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1703936 || all params: 750979072 || trainable%: 0.22689527092440734\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    #target_modules=[\"query_key_value\"],\n",
    "    bias=\"none\",\n",
    "    task_type= \"CAUSAL_LM\"# fill the gaph\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config) # fill the gap, using lora weights\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5H1bBQaSNVsr"
   },
   "source": [
    "## <b>Test the model before finetuning:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sRW7HPX6WCmI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: What equipment do I need for rock climbing?\n",
      "<assistant>: \n"
     ]
    }
   ],
   "source": [
    "prompt = \"<human>: What equipment do I need for rock climbing?\\n<assistant>: \"\n",
    " # # fill the gap, prompt of the format: \"<human>: What equipment do I need for rock climbing?  \\n <assistant>: \", with an empty response from the assistant\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 200\n",
    "generation_config.temperature = 0.7\n",
    "generation_config.top_p = 0.7\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "#generation_config.do_sample = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8isiEVs-eUy"
   },
   "source": [
    "Question: what does the temperature do in the above cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer \n",
    "Temperature adjusts the randomness of a model's output. When the temperature is set below 1, the model becomes more deterministic, favoring more predictable and likely next tokens. Conversely, if the temperature is set above 1, the output becomes more random as the model is encouraged to explore less likely words, which can lead to a greater variety but may also introduce errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DnmKXlqSWPQq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: What equipment do I need for rock climbing?\n",
      "<assistant>: 1. What is the best equipment for rock climbing?\n",
      "<assistant>: 2. What is the best equipment for rock climbing?\n",
      "<assistant>: 3. What is the best equipment for rock climbing?\n",
      "<assistant>: 4. What is the best equipment for rock climbing?\n",
      "<assistant>: 5. What is the best equipment for rock climbing?\n",
      "<assistant>: 6. What is the best equipment for rock climbing?\n",
      "<assistant>: 7. What is the best equipment for rock climbing?\n",
      "<assistant>: 8. What is the best equipment for rock climbing?\n",
      "<assistant>: 9. What is the best equipment for rock climbing?\n",
      "<assistant>: 10. What is the best equipment for rock climbing?\n",
      "<assistant>: 11. What is the best equipment for rock climbing?\n",
      "<assistant>: 12. What is the best equipment for rock climbing?\n",
      "<assistant>: 13. What is the best equipment for rock climbing?\n",
      "<assistant>: 14. What is the\n",
      "CPU times: total: 12.5 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbhQySqVMo2T"
   },
   "source": [
    "## <b>Loading the question/answer dataset from HuggingFace:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "2zR54r9AWQ-d",
    "outputId": "d9b56f9e-3ac6-4b87-8d2e-a9dbc0cd24f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>demonstration</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, I want to learn to play horseshoes. Can yo...</td>\n",
       "      <td>I can, but maybe I should begin by telling you...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I teach kids to meditate?</td>\n",
       "      <td>Great question! That’s a really useful skill t...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you tell me the steps for getting a harbor...</td>\n",
       "      <td>Sure. I believe you’ll need a copy of the mari...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I store food if I don't have a pantry?</td>\n",
       "      <td>You could store the food in a refrigerator, th...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are some good novels for a 9 year old?</td>\n",
       "      <td>That depends on the 9 year old, but if they li...</td>\n",
       "      <td>{'source': 'helpful-anthropic-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147701</th>\n",
       "      <td>Given the following sentence, classify it into...</td>\n",
       "      <td>Fact</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147702</th>\n",
       "      <td>A person wants to write a book. he/she writes ...</td>\n",
       "      <td>Chapter 1 - The History of China\\nChapter 2 - ...</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147703</th>\n",
       "      <td>Tell me how you would make a popular app game.</td>\n",
       "      <td>I would make a game that is similar to 2048. T...</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147704</th>\n",
       "      <td>Describe your dream house to me.\\n\\nOutput:</td>\n",
       "      <td>My dream house is a two-story building with a ...</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147705</th>\n",
       "      <td>Task: Rewrite the given sentence using only on...</td>\n",
       "      <td>Dog</td>\n",
       "      <td>{'source': 'helpful-self-instruct-raw'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147706 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instruction  \\\n",
       "0       Hi, I want to learn to play horseshoes. Can yo...   \n",
       "1                        How do I teach kids to meditate?   \n",
       "2       Can you tell me the steps for getting a harbor...   \n",
       "3          How can I store food if I don't have a pantry?   \n",
       "4             what are some good novels for a 9 year old?   \n",
       "...                                                   ...   \n",
       "147701  Given the following sentence, classify it into...   \n",
       "147702  A person wants to write a book. he/she writes ...   \n",
       "147703     Tell me how you would make a popular app game.   \n",
       "147704        Describe your dream house to me.\\n\\nOutput:   \n",
       "147705  Task: Rewrite the given sentence using only on...   \n",
       "\n",
       "                                            demonstration  \\\n",
       "0       I can, but maybe I should begin by telling you...   \n",
       "1       Great question! That’s a really useful skill t...   \n",
       "2       Sure. I believe you’ll need a copy of the mari...   \n",
       "3       You could store the food in a refrigerator, th...   \n",
       "4       That depends on the 9 year old, but if they li...   \n",
       "...                                                   ...   \n",
       "147701                                               Fact   \n",
       "147702  Chapter 1 - The History of China\\nChapter 2 - ...   \n",
       "147703  I would make a game that is similar to 2048. T...   \n",
       "147704  My dream house is a two-story building with a ...   \n",
       "147705                                                Dog   \n",
       "\n",
       "                                           meta  \n",
       "0           {'source': 'helpful-anthropic-raw'}  \n",
       "1           {'source': 'helpful-anthropic-raw'}  \n",
       "2           {'source': 'helpful-anthropic-raw'}  \n",
       "3           {'source': 'helpful-anthropic-raw'}  \n",
       "4           {'source': 'helpful-anthropic-raw'}  \n",
       "...                                         ...  \n",
       "147701  {'source': 'helpful-self-instruct-raw'}  \n",
       "147702  {'source': 'helpful-self-instruct-raw'}  \n",
       "147703  {'source': 'helpful-self-instruct-raw'}  \n",
       "147704  {'source': 'helpful-self-instruct-raw'}  \n",
       "147705  {'source': 'helpful-self-instruct-raw'}  \n",
       "\n",
       "[147706 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"HuggingFaceH4/helpful-instructions\")\n",
    "pd.DataFrame(data[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oSZX9UcNBsu"
   },
   "source": [
    "## <b>Preparing the finetuning data:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cQiJpF41WZEc"
   },
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    question = data_point['instruction']\n",
    "    response = data_point['demonstration']\n",
    "    return f\"<human>: {question}\\n<assistant>: {response}\"\n",
    "    # fill the gap, transform the data into prompts of the format: \"<human>: question?  \\n <assistant>: response\"\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
    "    return tokenized_full_prompt\n",
    "\n",
    "data = data[\"train\"].shuffle(seed=42).map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGfbqJ_cNHDa"
   },
   "source": [
    "## <b>Finetuning:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sjBMVb6yW_74",
    "outputId": "de815bab-bd72-4a80-9048-2573a7002913"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac9a988aaaf4221bc97937795abd570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\MHA.cpp:676.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5725, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 0.0}\n",
      "{'loss': 2.4003, 'grad_norm': 1.5642026662826538, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.0}\n",
      "{'loss': 2.8986, 'grad_norm': 1.774344801902771, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 2.5586, 'grad_norm': 1.654936671257019, 'learning_rate': 4e-05, 'epoch': 0.0}\n",
      "{'loss': 3.0194, 'grad_norm': 1.9287158250808716, 'learning_rate': 5.333333333333333e-05, 'epoch': 0.0}\n",
      "{'loss': 2.6012, 'grad_norm': 1.0093914270401, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.0654, 'grad_norm': 2.0078952312469482, 'learning_rate': 8e-05, 'epoch': 0.0}\n",
      "{'loss': 2.5509, 'grad_norm': 2.088275909423828, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 2.9975, 'grad_norm': 2.637000322341919, 'learning_rate': 0.00010666666666666667, 'epoch': 0.0}\n",
      "{'loss': 2.8589, 'grad_norm': 2.1615777015686035, 'learning_rate': 0.00012, 'epoch': 0.0}\n",
      "{'loss': 2.4632, 'grad_norm': 1.627706527709961, 'learning_rate': 0.00013333333333333334, 'epoch': 0.0}\n",
      "{'loss': 2.76, 'grad_norm': 2.74186372756958, 'learning_rate': 0.00014666666666666666, 'epoch': 0.0}\n",
      "{'loss': 2.7894, 'grad_norm': 2.927905559539795, 'learning_rate': 0.00016, 'epoch': 0.0}\n",
      "{'loss': 2.3021, 'grad_norm': 1.947173833847046, 'learning_rate': 0.00017333333333333334, 'epoch': 0.0}\n",
      "{'loss': 2.7684, 'grad_norm': 2.0006871223449707, 'learning_rate': 0.0001866666666666667, 'epoch': 0.0}\n",
      "{'loss': 1.5281, 'grad_norm': 1.1230592727661133, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
      "{'loss': 3.0812, 'grad_norm': 3.213486433029175, 'learning_rate': 0.00019999392458943432, 'epoch': 0.0}\n",
      "{'loss': 2.6375, 'grad_norm': 3.1973462104797363, 'learning_rate': 0.00019997569909594947, 'epoch': 0.0}\n",
      "{'loss': 2.5993, 'grad_norm': 3.068070411682129, 'learning_rate': 0.00019994532573409262, 'epoch': 0.0}\n",
      "{'loss': 2.299, 'grad_norm': 3.016206741333008, 'learning_rate': 0.0001999028081944766, 'epoch': 0.0}\n",
      "{'loss': 2.4754, 'grad_norm': 4.059586524963379, 'learning_rate': 0.00019984815164333163, 'epoch': 0.0}\n",
      "{'loss': 2.7945, 'grad_norm': 6.3723249435424805, 'learning_rate': 0.00019978136272187747, 'epoch': 0.0}\n",
      "{'loss': 1.6827, 'grad_norm': 2.12646746635437, 'learning_rate': 0.0001997024495455165, 'epoch': 0.0}\n",
      "{'loss': 2.7313, 'grad_norm': 6.068493366241455, 'learning_rate': 0.00019961142170284762, 'epoch': 0.0}\n",
      "{'loss': 2.4634, 'grad_norm': 4.959310531616211, 'learning_rate': 0.00019950829025450114, 'epoch': 0.0}\n",
      "{'loss': 2.0797, 'grad_norm': 2.6430752277374268, 'learning_rate': 0.00019939306773179497, 'epoch': 0.0}\n",
      "{'loss': 2.3681, 'grad_norm': 3.917179822921753, 'learning_rate': 0.00019926576813521164, 'epoch': 0.0}\n",
      "{'loss': 2.5531, 'grad_norm': 4.013669967651367, 'learning_rate': 0.00019912640693269752, 'epoch': 0.0}\n",
      "{'loss': 2.1069, 'grad_norm': 2.9047253131866455, 'learning_rate': 0.000198975001057783, 'epoch': 0.0}\n",
      "{'loss': 1.8884, 'grad_norm': 2.579050064086914, 'learning_rate': 0.00019881156890752517, 'epoch': 0.0}\n",
      "{'loss': 2.0051, 'grad_norm': 4.967179775238037, 'learning_rate': 0.00019863613034027224, 'epoch': 0.0}\n",
      "{'loss': 2.2966, 'grad_norm': 4.35268497467041, 'learning_rate': 0.00019844870667325073, 'epoch': 0.0}\n",
      "{'loss': 2.3769, 'grad_norm': 3.262359619140625, 'learning_rate': 0.00019824932067997515, 'epoch': 0.0}\n",
      "{'loss': 1.8116, 'grad_norm': 2.837973117828369, 'learning_rate': 0.00019803799658748094, 'epoch': 0.0}\n",
      "{'loss': 2.3957, 'grad_norm': 3.849032402038574, 'learning_rate': 0.00019781476007338058, 'epoch': 0.0}\n",
      "{'loss': 2.3884, 'grad_norm': 3.5373570919036865, 'learning_rate': 0.00019757963826274357, 'epoch': 0.0}\n",
      "{'loss': 2.0823, 'grad_norm': 2.5339577198028564, 'learning_rate': 0.0001973326597248006, 'epoch': 0.0}\n",
      "{'loss': 1.9158, 'grad_norm': 2.837217330932617, 'learning_rate': 0.000197073854469472, 'epoch': 0.0}\n",
      "{'loss': 2.0302, 'grad_norm': 2.621760368347168, 'learning_rate': 0.0001968032539437215, 'epoch': 0.0}\n",
      "{'loss': 2.2691, 'grad_norm': 3.60056734085083, 'learning_rate': 0.00019652089102773488, 'epoch': 0.0}\n",
      "{'loss': 2.2468, 'grad_norm': 3.567415237426758, 'learning_rate': 0.00019622680003092503, 'epoch': 0.0}\n",
      "{'loss': 2.2373, 'grad_norm': 3.470658302307129, 'learning_rate': 0.00019592101668776298, 'epoch': 0.0}\n",
      "{'loss': 2.1299, 'grad_norm': 3.8054988384246826, 'learning_rate': 0.00019560357815343577, 'epoch': 0.0}\n",
      "{'loss': 1.8334, 'grad_norm': 3.08469557762146, 'learning_rate': 0.0001952745229993319, 'epoch': 0.0}\n",
      "{'loss': 2.0903, 'grad_norm': 4.192563056945801, 'learning_rate': 0.00019493389120835462, 'epoch': 0.0}\n",
      "{'loss': 2.3786, 'grad_norm': 3.9476985931396484, 'learning_rate': 0.00019458172417006347, 'epoch': 0.0}\n",
      "{'loss': 2.0215, 'grad_norm': 3.4313337802886963, 'learning_rate': 0.00019421806467564544, 'epoch': 0.0}\n",
      "{'loss': 2.221, 'grad_norm': 2.502620220184326, 'learning_rate': 0.00019384295691271522, 'epoch': 0.0}\n",
      "{'loss': 2.0717, 'grad_norm': 3.152815818786621, 'learning_rate': 0.0001934564464599461, 'epoch': 0.0}\n",
      "{'loss': 1.9582, 'grad_norm': 3.8849973678588867, 'learning_rate': 0.00019305858028153186, 'epoch': 0.0}\n",
      "{'loss': 1.851, 'grad_norm': 3.3495113849639893, 'learning_rate': 0.00019264940672148018, 'epoch': 0.0}\n",
      "{'loss': 2.2166, 'grad_norm': 4.516751766204834, 'learning_rate': 0.00019222897549773848, 'epoch': 0.0}\n",
      "{'loss': 2.1441, 'grad_norm': 4.355230331420898, 'learning_rate': 0.0001917973376961527, 'epoch': 0.0}\n",
      "{'loss': 2.2964, 'grad_norm': 2.456965446472168, 'learning_rate': 0.0001913545457642601, 'epoch': 0.0}\n",
      "{'loss': 1.9789, 'grad_norm': 3.1196396350860596, 'learning_rate': 0.00019090065350491626, 'epoch': 0.0}\n",
      "{'loss': 2.0092, 'grad_norm': 3.5361037254333496, 'learning_rate': 0.00019043571606975777, 'epoch': 0.0}\n",
      "{'loss': 2.2206, 'grad_norm': 3.0388474464416504, 'learning_rate': 0.0001899597899525007, 'epoch': 0.0}\n",
      "{'loss': 2.0997, 'grad_norm': 4.74462890625, 'learning_rate': 0.00018947293298207635, 'epoch': 0.0}\n",
      "{'loss': 2.3976, 'grad_norm': 4.821691036224365, 'learning_rate': 0.00018897520431560434, 'epoch': 0.0}\n",
      "{'loss': 2.1385, 'grad_norm': 2.939371109008789, 'learning_rate': 0.0001884666644312046, 'epoch': 0.0}\n",
      "{'loss': 2.1664, 'grad_norm': 5.885988235473633, 'learning_rate': 0.0001879473751206489, 'epoch': 0.0}\n",
      "{'loss': 2.071, 'grad_norm': 3.1448090076446533, 'learning_rate': 0.00018741739948185257, 'epoch': 0.0}\n",
      "{'loss': 1.7477, 'grad_norm': 3.317784070968628, 'learning_rate': 0.00018687680191120743, 'epoch': 0.0}\n",
      "{'loss': 1.8459, 'grad_norm': 3.836932420730591, 'learning_rate': 0.00018632564809575742, 'epoch': 0.0}\n",
      "{'loss': 2.2709, 'grad_norm': 3.5346174240112305, 'learning_rate': 0.00018576400500521672, 'epoch': 0.0}\n",
      "{'loss': 1.8646, 'grad_norm': 3.0118792057037354, 'learning_rate': 0.00018519194088383273, 'epoch': 0.0}\n",
      "{'loss': 2.0207, 'grad_norm': 2.710468292236328, 'learning_rate': 0.00018460952524209355, 'epoch': 0.0}\n",
      "{'loss': 1.7659, 'grad_norm': 3.2438395023345947, 'learning_rate': 0.00018401682884828212, 'epoch': 0.0}\n",
      "{'loss': 2.006, 'grad_norm': 1.830588698387146, 'learning_rate': 0.000183413923719877, 'epoch': 0.0}\n",
      "{'loss': 2.4778, 'grad_norm': 2.644178867340088, 'learning_rate': 0.00018280088311480201, 'epoch': 0.0}\n",
      "{'loss': 1.8298, 'grad_norm': 3.579303503036499, 'learning_rate': 0.0001821777815225245, 'epoch': 0.0}\n",
      "{'loss': 2.083, 'grad_norm': 2.946575880050659, 'learning_rate': 0.00018154469465500448, 'epoch': 0.0}\n",
      "{'loss': 1.7167, 'grad_norm': 2.308566093444824, 'learning_rate': 0.00018090169943749476, 'epoch': 0.0}\n",
      "{'loss': 2.0648, 'grad_norm': 3.2387940883636475, 'learning_rate': 0.0001802488739991941, 'epoch': 0.0}\n",
      "{'loss': 2.2835, 'grad_norm': 3.6390318870544434, 'learning_rate': 0.00017958629766375386, 'epoch': 0.0}\n",
      "{'loss': 1.9472, 'grad_norm': 1.9857616424560547, 'learning_rate': 0.00017891405093963938, 'epoch': 0.0}\n",
      "{'loss': 2.1548, 'grad_norm': 3.8612570762634277, 'learning_rate': 0.00017823221551034764, 'epoch': 0.0}\n",
      "{'loss': 1.8925, 'grad_norm': 2.1938390731811523, 'learning_rate': 0.00017754087422448215, 'epoch': 0.0}\n",
      "{'loss': 1.716, 'grad_norm': 3.2823173999786377, 'learning_rate': 0.00017684011108568592, 'epoch': 0.0}\n",
      "{'loss': 1.5193, 'grad_norm': 2.2250149250030518, 'learning_rate': 0.00017613001124243446, 'epoch': 0.0}\n",
      "{'loss': 1.3411, 'grad_norm': 2.1797873973846436, 'learning_rate': 0.00017541066097768963, 'epoch': 0.0}\n",
      "{'loss': 2.0146, 'grad_norm': 4.9251909255981445, 'learning_rate': 0.0001746821476984154, 'epoch': 0.0}\n",
      "{'loss': 1.9365, 'grad_norm': 4.487407684326172, 'learning_rate': 0.00017394455992495722, 'epoch': 0.0}\n",
      "{'loss': 2.1504, 'grad_norm': 3.6772592067718506, 'learning_rate': 0.00017319798728028619, 'epoch': 0.0}\n",
      "{'loss': 1.6384, 'grad_norm': 2.741563320159912, 'learning_rate': 0.00017244252047910892, 'epoch': 0.0}\n",
      "{'loss': 1.9917, 'grad_norm': 2.953345537185669, 'learning_rate': 0.00017167825131684513, 'epoch': 0.0}\n",
      "{'loss': 1.8792, 'grad_norm': 3.111063003540039, 'learning_rate': 0.00017090527265847377, 'epoch': 0.0}\n",
      "{'loss': 1.623, 'grad_norm': 2.479240655899048, 'learning_rate': 0.00017012367842724887, 'epoch': 0.0}\n",
      "{'loss': 1.9718, 'grad_norm': 3.441950798034668, 'learning_rate': 0.00016933356359328757, 'epoch': 0.0}\n",
      "{'loss': 1.9621, 'grad_norm': 2.6721811294555664, 'learning_rate': 0.00016853502416203, 'epoch': 0.0}\n",
      "{'loss': 2.3523, 'grad_norm': 4.6646904945373535, 'learning_rate': 0.00016772815716257412, 'epoch': 0.0}\n",
      "{'loss': 2.1299, 'grad_norm': 3.2494568824768066, 'learning_rate': 0.00016691306063588583, 'epoch': 0.0}\n",
      "{'loss': 2.0289, 'grad_norm': 3.601195812225342, 'learning_rate': 0.00016608983362288612, 'epoch': 0.0}\n",
      "{'loss': 1.8067, 'grad_norm': 2.9691386222839355, 'learning_rate': 0.00016525857615241687, 'epoch': 0.0}\n",
      "{'loss': 1.8796, 'grad_norm': 3.600087881088257, 'learning_rate': 0.00016441938922908645, 'epoch': 0.0}\n",
      "{'loss': 1.9456, 'grad_norm': 2.3881242275238037, 'learning_rate': 0.00016357237482099684, 'epoch': 0.0}\n",
      "{'loss': 1.615, 'grad_norm': 3.674077272415161, 'learning_rate': 0.0001627176358473537, 'epoch': 0.0}\n",
      "{'loss': 1.6449, 'grad_norm': 3.574025869369507, 'learning_rate': 0.00016185527616596095, 'epoch': 0.0}\n",
      "{'loss': 2.0048, 'grad_norm': 2.456212043762207, 'learning_rate': 0.00016098540056060093, 'epoch': 0.0}\n",
      "{'loss': 1.7345, 'grad_norm': 3.1175894737243652, 'learning_rate': 0.00016010811472830252, 'epoch': 0.0}\n",
      "{'loss': 1.5578, 'grad_norm': 3.1295337677001953, 'learning_rate': 0.00015922352526649803, 'epoch': 0.0}\n",
      "{'loss': 1.8994, 'grad_norm': 4.772888660430908, 'learning_rate': 0.00015833173966007066, 'epoch': 0.0}\n",
      "{'loss': 2.0764, 'grad_norm': 3.1557540893554688, 'learning_rate': 0.00015743286626829437, 'epoch': 0.0}\n",
      "{'loss': 1.8968, 'grad_norm': 2.4767374992370605, 'learning_rate': 0.0001565270143116672, 'epoch': 0.0}\n",
      "{'loss': 1.4522, 'grad_norm': 2.3937571048736572, 'learning_rate': 0.00015561429385864005, 'epoch': 0.0}\n",
      "{'loss': 2.1742, 'grad_norm': 2.8380935192108154, 'learning_rate': 0.0001546948158122427, 'epoch': 0.0}\n",
      "{'loss': 2.3222, 'grad_norm': 2.692923069000244, 'learning_rate': 0.00015376869189660783, 'epoch': 0.0}\n",
      "{'loss': 1.9131, 'grad_norm': 2.8957583904266357, 'learning_rate': 0.0001528360346433959, 'epoch': 0.0}\n",
      "{'loss': 1.6649, 'grad_norm': 2.831355094909668, 'learning_rate': 0.00015189695737812152, 'epoch': 0.0}\n",
      "{'loss': 1.9019, 'grad_norm': 2.993926525115967, 'learning_rate': 0.00015095157420638348, 'epoch': 0.0}\n",
      "{'loss': 1.7397, 'grad_norm': 3.0896637439727783, 'learning_rate': 0.00015000000000000001, 'epoch': 0.0}\n",
      "{'loss': 2.0668, 'grad_norm': 2.6175625324249268, 'learning_rate': 0.00014904235038305083, 'epoch': 0.0}\n",
      "{'loss': 1.9768, 'grad_norm': 2.9044032096862793, 'learning_rate': 0.00014807874171782795, 'epoch': 0.0}\n",
      "{'loss': 2.1857, 'grad_norm': 5.138264179229736, 'learning_rate': 0.00014710929109069674, 'epoch': 0.0}\n",
      "{'loss': 1.5782, 'grad_norm': 3.0707528591156006, 'learning_rate': 0.0001461341162978688, 'epoch': 0.0}\n",
      "{'loss': 1.9022, 'grad_norm': 3.520711660385132, 'learning_rate': 0.00014515333583108896, 'epoch': 0.0}\n",
      "{'loss': 1.6408, 'grad_norm': 2.825408697128296, 'learning_rate': 0.0001441670688632374, 'epoch': 0.0}\n",
      "{'loss': 1.9737, 'grad_norm': 3.2961766719818115, 'learning_rate': 0.00014317543523384928, 'epoch': 0.0}\n",
      "{'loss': 2.0985, 'grad_norm': 3.566481351852417, 'learning_rate': 0.00014217855543455322, 'epoch': 0.0}\n",
      "{'loss': 2.0756, 'grad_norm': 2.980377674102783, 'learning_rate': 0.0001411765505944305, 'epoch': 0.0}\n",
      "{'loss': 1.5929, 'grad_norm': 3.810999631881714, 'learning_rate': 0.00014016954246529696, 'epoch': 0.0}\n",
      "{'loss': 1.7345, 'grad_norm': 3.639930009841919, 'learning_rate': 0.00013915765340690917, 'epoch': 0.0}\n",
      "{'loss': 1.9893, 'grad_norm': 4.0749945640563965, 'learning_rate': 0.0001381410063720966, 'epoch': 0.0}\n",
      "{'loss': 1.9547, 'grad_norm': 4.34193754196167, 'learning_rate': 0.00013711972489182208, 'epoch': 0.0}\n",
      "{'loss': 2.3589, 'grad_norm': 3.515911817550659, 'learning_rate': 0.0001360939330601715, 'epoch': 0.0}\n",
      "{'loss': 1.9706, 'grad_norm': 2.9109394550323486, 'learning_rate': 0.00013506375551927547, 'epoch': 0.0}\n",
      "{'loss': 1.7164, 'grad_norm': 2.967052698135376, 'learning_rate': 0.00013402931744416433, 'epoch': 0.0}\n",
      "{'loss': 2.7935, 'grad_norm': 4.620983600616455, 'learning_rate': 0.0001329907445275583, 'epoch': 0.0}\n",
      "{'loss': 2.0228, 'grad_norm': 3.96655011177063, 'learning_rate': 0.0001319481629645948, 'epoch': 0.0}\n",
      "{'loss': 1.5579, 'grad_norm': 2.949964761734009, 'learning_rate': 0.00013090169943749476, 'epoch': 0.0}\n",
      "{'loss': 2.1638, 'grad_norm': 2.5425233840942383, 'learning_rate': 0.00012985148110016947, 'epoch': 0.0}\n",
      "{'loss': 1.6173, 'grad_norm': 3.054759979248047, 'learning_rate': 0.00012879763556277062, 'epoch': 0.0}\n",
      "{'loss': 1.788, 'grad_norm': 2.5333096981048584, 'learning_rate': 0.00012774029087618446, 'epoch': 0.0}\n",
      "{'loss': 1.663, 'grad_norm': 2.4750702381134033, 'learning_rate': 0.00012667957551647262, 'epoch': 0.0}\n",
      "{'loss': 2.0041, 'grad_norm': 2.6246790885925293, 'learning_rate': 0.00012561561836926113, 'epoch': 0.0}\n",
      "{'loss': 1.7805, 'grad_norm': 2.1076698303222656, 'learning_rate': 0.00012454854871407994, 'epoch': 0.0}\n",
      "{'loss': 1.8014, 'grad_norm': 2.313600540161133, 'learning_rate': 0.0001234784962086541, 'epoch': 0.0}\n",
      "{'loss': 2.2713, 'grad_norm': 7.492212295532227, 'learning_rate': 0.0001224055908731496, 'epoch': 0.0}\n",
      "{'loss': 1.7247, 'grad_norm': 2.440218687057495, 'learning_rate': 0.0001213299630743747, 'epoch': 0.0}\n",
      "{'loss': 1.5408, 'grad_norm': 2.830872058868408, 'learning_rate': 0.00012025174350993922, 'epoch': 0.0}\n",
      "{'loss': 2.0249, 'grad_norm': 2.3663976192474365, 'learning_rate': 0.00011917106319237386, 'epoch': 0.0}\n",
      "{'loss': 1.8974, 'grad_norm': 4.440623760223389, 'learning_rate': 0.000118088053433211, 'epoch': 0.0}\n",
      "{'loss': 2.3443, 'grad_norm': 3.3052799701690674, 'learning_rate': 0.00011700284582702932, 'epoch': 0.0}\n",
      "{'loss': 2.4529, 'grad_norm': 3.4926917552948, 'learning_rate': 0.00011591557223546395, 'epoch': 0.0}\n",
      "{'loss': 1.6319, 'grad_norm': 2.459550380706787, 'learning_rate': 0.0001148263647711842, 'epoch': 0.0}\n",
      "{'loss': 1.9997, 'grad_norm': 3.8467178344726562, 'learning_rate': 0.00011373535578184082, 'epoch': 0.0}\n",
      "{'loss': 1.7372, 'grad_norm': 1.9366424083709717, 'learning_rate': 0.00011264267783398463, 'epoch': 0.0}\n",
      "{'loss': 1.595, 'grad_norm': 1.9039758443832397, 'learning_rate': 0.00011154846369695863, 'epoch': 0.0}\n",
      "{'loss': 2.1606, 'grad_norm': 2.367523670196533, 'learning_rate': 0.00011045284632676536, 'epoch': 0.0}\n",
      "{'loss': 2.2375, 'grad_norm': 3.060335874557495, 'learning_rate': 0.00010935595884991178, 'epoch': 0.0}\n",
      "{'loss': 1.7518, 'grad_norm': 2.695420742034912, 'learning_rate': 0.00010825793454723325, 'epoch': 0.0}\n",
      "{'loss': 2.0525, 'grad_norm': 2.215775728225708, 'learning_rate': 0.00010715890683769872, 'epoch': 0.0}\n",
      "{'loss': 1.9935, 'grad_norm': 5.237480640411377, 'learning_rate': 0.00010605900926219939, 'epoch': 0.0}\n",
      "{'loss': 2.7067, 'grad_norm': 3.503368854522705, 'learning_rate': 0.00010495837546732224, 'epoch': 0.0}\n",
      "{'loss': 1.8725, 'grad_norm': 2.522887945175171, 'learning_rate': 0.00010385713918911105, 'epoch': 0.0}\n",
      "{'loss': 1.824, 'grad_norm': 3.5685887336730957, 'learning_rate': 0.00010275543423681621, 'epoch': 0.0}\n",
      "{'loss': 1.7549, 'grad_norm': 3.0182759761810303, 'learning_rate': 0.00010165339447663587, 'epoch': 0.0}\n",
      "{'loss': 1.7794, 'grad_norm': 3.7828850746154785, 'learning_rate': 0.00010055115381545006, 'epoch': 0.0}\n",
      "{'loss': 2.2757, 'grad_norm': 3.1120541095733643, 'learning_rate': 9.944884618454996e-05, 'epoch': 0.0}\n",
      "{'loss': 1.9083, 'grad_norm': 2.9299869537353516, 'learning_rate': 9.834660552336415e-05, 'epoch': 0.0}\n",
      "{'loss': 2.0682, 'grad_norm': 2.3965935707092285, 'learning_rate': 9.724456576318381e-05, 'epoch': 0.0}\n",
      "{'loss': 1.8228, 'grad_norm': 2.374765396118164, 'learning_rate': 9.614286081088895e-05, 'epoch': 0.0}\n",
      "{'loss': 1.6385, 'grad_norm': 1.9591563940048218, 'learning_rate': 9.504162453267777e-05, 'epoch': 0.0}\n",
      "{'loss': 1.9054, 'grad_norm': 2.7983503341674805, 'learning_rate': 9.394099073780066e-05, 'epoch': 0.0}\n",
      "{'loss': 2.0394, 'grad_norm': 3.3730196952819824, 'learning_rate': 9.284109316230133e-05, 'epoch': 0.0}\n",
      "{'loss': 1.7429, 'grad_norm': 2.9159672260284424, 'learning_rate': 9.174206545276677e-05, 'epoch': 0.0}\n",
      "{'loss': 1.8422, 'grad_norm': 3.613187313079834, 'learning_rate': 9.064404115008823e-05, 'epoch': 0.0}\n",
      "{'loss': 1.5424, 'grad_norm': 3.348759889602661, 'learning_rate': 8.954715367323468e-05, 'epoch': 0.0}\n",
      "{'loss': 2.029, 'grad_norm': 3.8384199142456055, 'learning_rate': 8.845153630304139e-05, 'epoch': 0.0}\n",
      "{'loss': 2.108, 'grad_norm': 3.0351436138153076, 'learning_rate': 8.735732216601538e-05, 'epoch': 0.0}\n",
      "{'loss': 2.0512, 'grad_norm': 2.265730381011963, 'learning_rate': 8.626464421815919e-05, 'epoch': 0.0}\n",
      "{'loss': 1.9611, 'grad_norm': 3.1006791591644287, 'learning_rate': 8.517363522881579e-05, 'epoch': 0.0}\n",
      "{'loss': 1.7464, 'grad_norm': 3.4438371658325195, 'learning_rate': 8.408442776453605e-05, 'epoch': 0.0}\n",
      "{'loss': 1.761, 'grad_norm': 2.55578875541687, 'learning_rate': 8.299715417297071e-05, 'epoch': 0.0}\n",
      "{'loss': 2.3203, 'grad_norm': 3.24373459815979, 'learning_rate': 8.191194656678904e-05, 'epoch': 0.0}\n",
      "{'loss': 2.5963, 'grad_norm': 3.462846517562866, 'learning_rate': 8.082893680762619e-05, 'epoch': 0.0}\n",
      "{'loss': 1.9603, 'grad_norm': 3.0160200595855713, 'learning_rate': 7.974825649006081e-05, 'epoch': 0.0}\n",
      "{'loss': 2.063, 'grad_norm': 3.156837224960327, 'learning_rate': 7.867003692562534e-05, 'epoch': 0.0}\n",
      "{'loss': 2.0067, 'grad_norm': 2.699615240097046, 'learning_rate': 7.759440912685042e-05, 'epoch': 0.0}\n",
      "{'loss': 1.8691, 'grad_norm': 2.2961790561676025, 'learning_rate': 7.652150379134592e-05, 'epoch': 0.0}\n",
      "{'loss': 1.9448, 'grad_norm': 2.742790937423706, 'learning_rate': 7.54514512859201e-05, 'epoch': 0.0}\n",
      "{'loss': 2.1292, 'grad_norm': 3.7703866958618164, 'learning_rate': 7.438438163073884e-05, 'epoch': 0.0}\n",
      "{'loss': 1.8825, 'grad_norm': 2.791100263595581, 'learning_rate': 7.332042448352738e-05, 'epoch': 0.0}\n",
      "{'loss': 1.9624, 'grad_norm': 2.707040786743164, 'learning_rate': 7.225970912381556e-05, 'epoch': 0.0}\n",
      "{'loss': 1.513, 'grad_norm': 2.2794928550720215, 'learning_rate': 7.12023644372294e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9104, 'grad_norm': 2.0056517124176025, 'learning_rate': 7.014851889983057e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9705, 'grad_norm': 2.773164749145508, 'learning_rate': 6.909830056250527e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9813, 'grad_norm': 3.3249359130859375, 'learning_rate': 6.80518370354052e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8947, 'grad_norm': 2.857611656188965, 'learning_rate': 6.700925547244173e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7865, 'grad_norm': 3.1929194927215576, 'learning_rate': 6.59706825558357e-05, 'epoch': 0.01}\n",
      "{'loss': 2.161, 'grad_norm': 2.8660359382629395, 'learning_rate': 6.493624448072457e-05, 'epoch': 0.01}\n",
      "{'loss': 1.4368, 'grad_norm': 2.620716094970703, 'learning_rate': 6.390606693982855e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0618, 'grad_norm': 3.060563802719116, 'learning_rate': 6.28802751081779e-05, 'epoch': 0.01}\n",
      "{'loss': 1.6467, 'grad_norm': 3.846508026123047, 'learning_rate': 6.185899362790339e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1036, 'grad_norm': 2.4693660736083984, 'learning_rate': 6.084234659309088e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9496, 'grad_norm': 5.089570999145508, 'learning_rate': 5.983045753470308e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9028, 'grad_norm': 3.322287082672119, 'learning_rate': 5.8823449405569516e-05, 'epoch': 0.01}\n",
      "{'loss': 2.4604, 'grad_norm': 3.9007468223571777, 'learning_rate': 5.78214445654468e-05, 'epoch': 0.01}\n",
      "{'loss': 1.6403, 'grad_norm': 2.386690616607666, 'learning_rate': 5.6824564766150726e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1135, 'grad_norm': 4.588735580444336, 'learning_rate': 5.58329311367626e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2972, 'grad_norm': 4.23418664932251, 'learning_rate': 5.484666416891109e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8829, 'grad_norm': 2.0428848266601562, 'learning_rate': 5.386588370213124e-05, 'epoch': 0.01}\n",
      "{'loss': 1.4118, 'grad_norm': 3.0930397510528564, 'learning_rate': 5.289070890930328e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3117, 'grad_norm': 2.3156418800354004, 'learning_rate': 5.1921258282172024e-05, 'epoch': 0.01}\n",
      "{'loss': 1.2865, 'grad_norm': 2.3365890979766846, 'learning_rate': 5.095764961694922e-05, 'epoch': 0.01}\n",
      "{'loss': 1.6705, 'grad_norm': 4.696538925170898, 'learning_rate': 5.000000000000002e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0553, 'grad_norm': 2.8598499298095703, 'learning_rate': 4.904842579361653e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0523, 'grad_norm': 2.5095999240875244, 'learning_rate': 4.810304262187852e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0421, 'grad_norm': 3.5160505771636963, 'learning_rate': 4.7163965356604125e-05, 'epoch': 0.01}\n",
      "{'loss': 2.3362, 'grad_norm': 4.5147624015808105, 'learning_rate': 4.623130810339219e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0475, 'grad_norm': 4.032384395599365, 'learning_rate': 4.530518418775733e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8526, 'grad_norm': 3.364163875579834, 'learning_rate': 4.438570614135994e-05, 'epoch': 0.01}\n",
      "{'loss': 1.402, 'grad_norm': 3.2969472408294678, 'learning_rate': 4.3472985688332815e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7575, 'grad_norm': 2.8847925662994385, 'learning_rate': 4.256713373170564e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8808, 'grad_norm': 2.882164478302002, 'learning_rate': 4.1668260339929385e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8771, 'grad_norm': 2.3464882373809814, 'learning_rate': 4.077647473350201e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9155, 'grad_norm': 3.212195873260498, 'learning_rate': 3.9891885271697496e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0094, 'grad_norm': 2.7102036476135254, 'learning_rate': 3.90145994393991e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7782, 'grad_norm': 3.079669952392578, 'learning_rate': 3.8144723834039066e-05, 'epoch': 0.01}\n",
      "{'loss': 1.831, 'grad_norm': 4.336352825164795, 'learning_rate': 3.7282364152646297e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7811, 'grad_norm': 3.4377684593200684, 'learning_rate': 3.642762517900322e-05, 'epoch': 0.01}\n",
      "{'loss': 1.604, 'grad_norm': 2.4443540573120117, 'learning_rate': 3.558061077091359e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0045, 'grad_norm': 8.581565856933594, 'learning_rate': 3.4741423847583134e-05, 'epoch': 0.01}\n",
      "{'loss': 1.933, 'grad_norm': 4.597568988800049, 'learning_rate': 3.3910166377113894e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1151, 'grad_norm': 2.761181354522705, 'learning_rate': 3.308693936411421e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8209, 'grad_norm': 2.747852325439453, 'learning_rate': 3.227184283742591e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0142, 'grad_norm': 4.296099662780762, 'learning_rate': 3.1464975837970036e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8564, 'grad_norm': 3.5231575965881348, 'learning_rate': 3.0666436406712485e-05, 'epoch': 0.01}\n",
      "{'loss': 1.4581, 'grad_norm': 2.50972843170166, 'learning_rate': 2.9876321572751144e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7189, 'grad_norm': 2.633941411972046, 'learning_rate': 2.9094727341526275e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0503, 'grad_norm': 3.8909056186676025, 'learning_rate': 2.8321748683154893e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0712, 'grad_norm': 3.5096805095672607, 'learning_rate': 2.7557479520891104e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7479, 'grad_norm': 2.7262864112854004, 'learning_rate': 2.680201271971382e-05, 'epoch': 0.01}\n",
      "{'loss': 1.5683, 'grad_norm': 3.6933083534240723, 'learning_rate': 2.6055440075042793e-05, 'epoch': 0.01}\n",
      "{'loss': 1.6893, 'grad_norm': 3.5243287086486816, 'learning_rate': 2.5317852301584643e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1782, 'grad_norm': 3.7390453815460205, 'learning_rate': 2.4589339022310386e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2331, 'grad_norm': 3.4337120056152344, 'learning_rate': 2.3869988757565543e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8577, 'grad_norm': 3.3318300247192383, 'learning_rate': 2.315988891431412e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7234, 'grad_norm': 3.168522357940674, 'learning_rate': 2.2459125775517852e-05, 'epoch': 0.01}\n",
      "{'loss': 1.5358, 'grad_norm': 3.572429656982422, 'learning_rate': 2.1767784489652343e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0177, 'grad_norm': 4.87119197845459, 'learning_rate': 2.1085949060360654e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0599, 'grad_norm': 3.3110158443450928, 'learning_rate': 2.0413702336246154e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7949, 'grad_norm': 2.7716939449310303, 'learning_rate': 1.9751126000805897e-05, 'epoch': 0.01}\n",
      "{'loss': 1.91, 'grad_norm': 2.639043092727661, 'learning_rate': 1.9098300562505266e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0837, 'grad_norm': 2.2347660064697266, 'learning_rate': 1.8455305344995533e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1003, 'grad_norm': 3.0557780265808105, 'learning_rate': 1.7822218477475494e-05, 'epoch': 0.01}\n",
      "{'loss': 2.051, 'grad_norm': 3.427154541015625, 'learning_rate': 1.7199116885197995e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7721, 'grad_norm': 2.754732847213745, 'learning_rate': 1.658607628012303e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8302, 'grad_norm': 4.511796474456787, 'learning_rate': 1.5983171151717923e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0024, 'grad_norm': 3.172760248184204, 'learning_rate': 1.5390474757906446e-05, 'epoch': 0.01}\n",
      "{'loss': 1.6204, 'grad_norm': 2.993466854095459, 'learning_rate': 1.4808059116167305e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8064, 'grad_norm': 3.5001988410949707, 'learning_rate': 1.4235994994783297e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0853, 'grad_norm': 3.6341190338134766, 'learning_rate': 1.3674351904242611e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1224, 'grad_norm': 3.991753339767456, 'learning_rate': 1.3123198088792576e-05, 'epoch': 0.01}\n",
      "{'loss': 2.203, 'grad_norm': 3.27180814743042, 'learning_rate': 1.2582600518147447e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9413, 'grad_norm': 2.9428889751434326, 'learning_rate': 1.2052624879351104e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8097, 'grad_norm': 2.962610960006714, 'learning_rate': 1.1533335568795412e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7724, 'grad_norm': 3.2162866592407227, 'learning_rate': 1.1024795684395694e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9896, 'grad_norm': 4.032971382141113, 'learning_rate': 1.0527067017923654e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0575, 'grad_norm': 4.089346408843994, 'learning_rate': 1.0040210047499288e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7248, 'grad_norm': 3.507049083709717, 'learning_rate': 9.564283930242257e-06, 'epoch': 0.01}\n",
      "{'loss': 2.0978, 'grad_norm': 3.221104860305786, 'learning_rate': 9.09934649508375e-06, 'epoch': 0.01}\n",
      "{'loss': 2.1856, 'grad_norm': 4.3462419509887695, 'learning_rate': 8.645454235739903e-06, 'epoch': 0.01}\n",
      "{'loss': 1.4809, 'grad_norm': 3.354526996612549, 'learning_rate': 8.202662303847298e-06, 'epoch': 0.01}\n",
      "{'loss': 1.7658, 'grad_norm': 3.5537033081054688, 'learning_rate': 7.771024502261526e-06, 'epoch': 0.01}\n",
      "{'loss': 1.7707, 'grad_norm': 2.5459704399108887, 'learning_rate': 7.350593278519824e-06, 'epoch': 0.01}\n",
      "{'loss': 2.0999, 'grad_norm': 3.5846896171569824, 'learning_rate': 6.941419718468168e-06, 'epoch': 0.01}\n",
      "{'loss': 2.3086, 'grad_norm': 4.078293323516846, 'learning_rate': 6.543553540053926e-06, 'epoch': 0.01}\n",
      "{'loss': 1.9905, 'grad_norm': 4.080393314361572, 'learning_rate': 6.157043087284798e-06, 'epoch': 0.01}\n",
      "{'loss': 2.2048, 'grad_norm': 3.1885671615600586, 'learning_rate': 5.78193532435457e-06, 'epoch': 0.01}\n",
      "{'loss': 1.6024, 'grad_norm': 2.2857894897460938, 'learning_rate': 5.418275829936537e-06, 'epoch': 0.01}\n",
      "{'loss': 1.9226, 'grad_norm': 2.945923089981079, 'learning_rate': 5.066108791645408e-06, 'epoch': 0.01}\n",
      "{'loss': 1.7071, 'grad_norm': 3.081325054168701, 'learning_rate': 4.72547700066811e-06, 'epoch': 0.01}\n",
      "{'loss': 1.6666, 'grad_norm': 3.5681073665618896, 'learning_rate': 4.3964218465642355e-06, 'epoch': 0.01}\n",
      "{'loss': 1.7497, 'grad_norm': 1.9845232963562012, 'learning_rate': 4.078983312237017e-06, 'epoch': 0.01}\n",
      "{'loss': 1.8195, 'grad_norm': 2.4309818744659424, 'learning_rate': 3.7731999690749585e-06, 'epoch': 0.01}\n",
      "{'loss': 1.6483, 'grad_norm': 2.2859699726104736, 'learning_rate': 3.4791089722651436e-06, 'epoch': 0.01}\n",
      "{'loss': 1.8399, 'grad_norm': 2.571244478225708, 'learning_rate': 3.1967460562785324e-06, 'epoch': 0.01}\n",
      "{'loss': 1.9605, 'grad_norm': 2.7255539894104004, 'learning_rate': 2.926145530528002e-06, 'epoch': 0.01}\n",
      "{'loss': 1.745, 'grad_norm': 3.23663330078125, 'learning_rate': 2.667340275199426e-06, 'epoch': 0.01}\n",
      "{'loss': 1.8829, 'grad_norm': 3.173074245452881, 'learning_rate': 2.420361737256438e-06, 'epoch': 0.01}\n",
      "{'loss': 1.7297, 'grad_norm': 3.7398521900177, 'learning_rate': 2.1852399266194314e-06, 'epoch': 0.01}\n",
      "{'loss': 2.5516, 'grad_norm': 4.810524940490723, 'learning_rate': 1.9620034125190644e-06, 'epoch': 0.01}\n",
      "{'loss': 1.5118, 'grad_norm': 3.416344404220581, 'learning_rate': 1.7506793200248506e-06, 'epoch': 0.01}\n",
      "{'loss': 1.7751, 'grad_norm': 3.1985528469085693, 'learning_rate': 1.5512933267492813e-06, 'epoch': 0.01}\n",
      "{'loss': 1.8792, 'grad_norm': 3.2604637145996094, 'learning_rate': 1.3638696597277679e-06, 'epoch': 0.01}\n",
      "{'loss': 1.8806, 'grad_norm': 3.1606738567352295, 'learning_rate': 1.18843109247484e-06, 'epoch': 0.01}\n",
      "{'loss': 1.9279, 'grad_norm': 3.5426957607269287, 'learning_rate': 1.0249989422169926e-06, 'epoch': 0.01}\n",
      "{'loss': 1.6448, 'grad_norm': 2.2720792293548584, 'learning_rate': 8.735930673024806e-07, 'epoch': 0.01}\n",
      "{'loss': 1.858, 'grad_norm': 2.6830248832702637, 'learning_rate': 7.342318647883595e-07, 'epoch': 0.01}\n",
      "{'loss': 2.0196, 'grad_norm': 3.400585651397705, 'learning_rate': 6.069322682050516e-07, 'epoch': 0.01}\n",
      "{'loss': 2.1515, 'grad_norm': 3.7841830253601074, 'learning_rate': 4.917097454988584e-07, 'epoch': 0.01}\n",
      "{'loss': 1.8251, 'grad_norm': 2.1964056491851807, 'learning_rate': 3.885782971524088e-07, 'epoch': 0.01}\n",
      "{'loss': 1.9908, 'grad_norm': 5.021731853485107, 'learning_rate': 2.9755045448351946e-07, 'epoch': 0.01}\n",
      "{'loss': 1.8301, 'grad_norm': 2.796043872833252, 'learning_rate': 2.1863727812254653e-07, 'epoch': 0.01}\n",
      "{'loss': 1.9877, 'grad_norm': 3.8019936084747314, 'learning_rate': 1.518483566683826e-07, 'epoch': 0.01}\n",
      "{'loss': 1.6644, 'grad_norm': 2.0013985633850098, 'learning_rate': 9.719180552341111e-08, 'epoch': 0.01}\n",
      "{'loss': 1.7478, 'grad_norm': 2.959084987640381, 'learning_rate': 5.467426590739511e-08, 'epoch': 0.01}\n",
      "{'loss': 1.8599, 'grad_norm': 2.7542991638183594, 'learning_rate': 2.430090405054486e-08, 'epoch': 0.01}\n",
      "{'loss': 1.7747, 'grad_norm': 2.9900400638580322, 'learning_rate': 6.075410565697937e-09, 'epoch': 0.01}\n",
      "{'train_runtime': 514.3682, 'train_samples_per_second': 2.333, 'train_steps_per_second': 0.583, 'train_loss': 1.997491771777471, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=1.997491771777471, metrics={'train_runtime': 514.3682, 'train_samples_per_second': 2.333, 'train_steps_per_second': 0.583, 'total_flos': 619367078596608.0, 'train_loss': 1.997491771777471, 'epoch': 0.008124246814618229})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = \"experiments\"\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=300,   # try more steps if you can\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B01QbSicXknK"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir experiments/runs --port 6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxy9b1f4Nqpd"
   },
   "source": [
    "## <b>Test the model after the finetuning:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tCYynNlrXDhf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: What equipment do I need for rock climbing?\n",
      "<assistant>: 1. A helmet. 2. A harness. 3. A rope. 4. A pair of climbing shoes. 5. A climbing wall. 6. A climbing guide. 7. A climbing instructor. 8. A climbing instructor’s guide. 9. A climbing instructor’s book. 10. A climbing instructor’s course. 11. A climbing instructor’s certificate. 12. A climbing instructor’s license. 13. A climbing instructor’s license. 14. A climbing instructor’s license. 15. A climbing instructor’s license. 16. A climbing instructor’s license. 17. A climbing instructor’s license. 18. A climbing instructor’s license. 19. A climbing instructor’s license. 20. A climbing instructor’s license. 21. A climbing instructor’s license. 22. A climbing instructor’s license. 23. A climbing instructor’s license. 24. A climbing instructor’s license.\n",
      "CPU times: total: 12.4 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CS_lwrJdXr-Y"
   },
   "outputs": [],
   "source": [
    "def generate_response(question: str) -> str:\n",
    "    prompt = f\"<human>: {question}\\n<assistant>: \" # fill the gap, transform the data into prompts of the format: \"<human>: question?  \\n <assistant>: \" with an empty response\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=encoding.input_ids,\n",
    "            attention_mask=encoding.attention_mask,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    assistant_start = \"<assistant>:\"\n",
    "    response_start = response.find(assistant_start)\n",
    "    return response[response_start + len(assistant_start) :].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sYaO6H_hXsvG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- What program can I use to edit video clips I took with my phone? \n",
      "\n",
      "I’m not sure what you mean by “edit video clips”.  Can you explain what you mean?  Are you trying to edit the video clips so that they are more visually appealing?  Are you trying to edit the video clips so that they are more informative?  Are you trying to edit the video clips so that they are more entertaining?  Are you trying to edit the video clips so that they are more engaging?  Are you trying to edit the video clips so that they are more informative?  Are you trying to edit the video clips so that they are more entertaining?  Are you trying to edit the video clips so that they are more engaging?  Are you trying to edit the video clips so that they are more informative?  Are you trying to edit the video clips so that they are more entertaining?  Are you trying to edit the video clips so that they are more engaging?  Are you trying to edit the video clips so that they are more informative?  Are\n",
      "\n",
      "\n",
      "\n",
      "- Do you know the reasons as to why people love coffee so much? \n",
      "\n",
      "1. It’s a great way to start the day. 2. It’s a great way to get energy. 3. It’s a great way to get a boost of energy. 4. It’s a great way to get a boost of energy. 5. It’s a great way to get a boost of energy. 6. It’s a great way to get a boost of energy. 7. It’s a great way to get a boost of energy. 8. It’s a great way to get a boost of energy. 9. It’s a great way to get a boost of energy. 10. It’s a great way to get a boost of energy. 11. It’s a great way to get a boost of energy. 12. It’s a great way to get a boost of energy. 13. It’s a great way to get a boost of energy. 14. It’s a great way to get a\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What program can I use to edit video clips I took with my phone?\"\n",
    "print('-', prompt,'\\n')\n",
    "print(generate_response(prompt))\n",
    "\n",
    "prompt = \"Do you know the reasons as to why people love coffee so much?\"\n",
    "print('\\n\\n\\n-', prompt, '\\n')\n",
    "print(generate_response(prompt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI3vebp86Zkk"
   },
   "source": [
    "# Part 2: DPO\n",
    "In this part we will use the instrcution tuned LLM to do direct preference optimization. see the paper: https://arxiv.org/abs/2305.18290\n",
    "\n",
    "DPO involves tuning the model on preference data, normally consists of a prompt, a prefered answer and a rejected answer.\n",
    "\n",
    "The core advantage of DPO is its ability to simultaneously bypass the explicit reward modeling step while avoiding the complexities of reinforcement learning optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IWSe-w97aHD"
   },
   "source": [
    "## Test the model before DPO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OYTh97h-J1aw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<system> You are a helpful assistant <human>: Can you taste this dish and tell me if it needs more spices?  \n",
      "<assistant>: \n"
     ]
    }
   ],
   "source": [
    "prompt_2 =f\"<system> You are a helpful assistant <human>: Can you taste this dish and tell me if it needs more spices?  \\n<assistant>: \" # fill the gap, prompt of the format: \"<system> You are a helpful assistant <human>: Can you taste this dish and tell me if it needs more spices?  \\n <assistant>: \", with an empty response from the assistant\n",
    "print(prompt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rgkX_YTpJ1aw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<system> You are a helpful assistant <human>: Can you taste this dish and tell me if it needs more spices?  \n",
      "<assistant>:  Yes, I can taste it.  It needs more spices.  I think it would be better if you added some chili powder.  It's not too spicy, but it could be better.  I think you should add some more chili powder.  It's not too spicy, but it could be better.  I think you should add some more chili powder.  It's not too spicy, but it could be better.  I think you should add some more chili powder.  It's not too spicy, but it could be better.  I think you should add some more chili powder.  It's not too spicy, but it could be better.  I think you should add some more chili powder.  It's not too spicy, but it could be better.  I think you should add some more chili powder.  It's not too spicy, but it could be better.  I think you should add some more chili powder.  It's not too\n",
      "CPU times: total: 17.1 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt_2, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m-mtxC87e1V"
   },
   "source": [
    "## Loading the preference data from Huggingface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "J46G0gigJ1aw",
    "outputId": "ced32b70-3011-4721-c4db-c0a7ba85267c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>question</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Can you taste this dish and tell me if it need...</td>\n",
       "      <td>I'm not capable of physically tasting the dish...</td>\n",
       "      <td>I can taste the dish remotely and I think it n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Can you smell this perfume and tell me if it's...</td>\n",
       "      <td>As a digital AI assistant, I don't have a phys...</td>\n",
       "      <td>I can smell the perfume, and it smells great. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Please turn off the lights in my room.</td>\n",
       "      <td>I'm a large language model, I don't have the c...</td>\n",
       "      <td>I can turn off the lights in your room remotel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What is the primary reason why many approximat...</td>\n",
       "      <td>The primary reason why many approximate attent...</td>\n",
       "      <td>Approximate attention methods haven't gained w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What are the properties of melanin that contri...</td>\n",
       "      <td>Melanin's photoprotective role can be attribut...</td>\n",
       "      <td>Melanin's photoprotective role is due to its a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What is the sound barrier?</td>\n",
       "      <td>The sound barrier, also known as the sonic bar...</td>\n",
       "      <td>The sound barrier is a physical wall that prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Is spinach a great source of dietary iron?</td>\n",
       "      <td>Spinach is a good source of dietary iron, but ...</td>\n",
       "      <td>Spinach is a poor source of dietary iron, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What challenges arise in training large langua...</td>\n",
       "      <td>Training large language models (LLMs) poses se...</td>\n",
       "      <td>The main challenge in training LLMs is the lac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>Does the theory of evolution explain the origi...</td>\n",
       "      <td>The theory of evolution explains how life on E...</td>\n",
       "      <td>The theory of evolution fully explains the ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>You are a helpful assistant</td>\n",
       "      <td>What is the key difference between the propose...</td>\n",
       "      <td>The key difference lies in the way the models ...</td>\n",
       "      <td>The key difference is that Self-Rewarding Lang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2179 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           system  \\\n",
       "0     You are a helpful assistant   \n",
       "1     You are a helpful assistant   \n",
       "2     You are a helpful assistant   \n",
       "3     You are a helpful assistant   \n",
       "4     You are a helpful assistant   \n",
       "...                           ...   \n",
       "2174  You are a helpful assistant   \n",
       "2175  You are a helpful assistant   \n",
       "2176  You are a helpful assistant   \n",
       "2177  You are a helpful assistant   \n",
       "2178  You are a helpful assistant   \n",
       "\n",
       "                                               question  \\\n",
       "0     Can you taste this dish and tell me if it need...   \n",
       "1     Can you smell this perfume and tell me if it's...   \n",
       "2                Please turn off the lights in my room.   \n",
       "3     What is the primary reason why many approximat...   \n",
       "4     What are the properties of melanin that contri...   \n",
       "...                                                 ...   \n",
       "2174                         What is the sound barrier?   \n",
       "2175         Is spinach a great source of dietary iron?   \n",
       "2176  What challenges arise in training large langua...   \n",
       "2177  Does the theory of evolution explain the origi...   \n",
       "2178  What is the key difference between the propose...   \n",
       "\n",
       "                                                 chosen  \\\n",
       "0     I'm not capable of physically tasting the dish...   \n",
       "1     As a digital AI assistant, I don't have a phys...   \n",
       "2     I'm a large language model, I don't have the c...   \n",
       "3     The primary reason why many approximate attent...   \n",
       "4     Melanin's photoprotective role can be attribut...   \n",
       "...                                                 ...   \n",
       "2174  The sound barrier, also known as the sonic bar...   \n",
       "2175  Spinach is a good source of dietary iron, but ...   \n",
       "2176  Training large language models (LLMs) poses se...   \n",
       "2177  The theory of evolution explains how life on E...   \n",
       "2178  The key difference lies in the way the models ...   \n",
       "\n",
       "                                               rejected  \n",
       "0     I can taste the dish remotely and I think it n...  \n",
       "1     I can smell the perfume, and it smells great. ...  \n",
       "2     I can turn off the lights in your room remotel...  \n",
       "3     Approximate attention methods haven't gained w...  \n",
       "4     Melanin's photoprotective role is due to its a...  \n",
       "...                                                 ...  \n",
       "2174  The sound barrier is a physical wall that prev...  \n",
       "2175  Spinach is a poor source of dietary iron, and ...  \n",
       "2176  The main challenge in training LLMs is the lac...  \n",
       "2177  The theory of evolution fully explains the ori...  \n",
       "2178  The key difference is that Self-Rewarding Lang...  \n",
       "\n",
       "[2179 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dpo = load_dataset(\"CultriX/llama70B-dpo-dataset\")\n",
    "pd.DataFrame(data_dpo[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1E4QFFI7pIc"
   },
   "source": [
    "## Preparing the data:\n",
    "\n",
    "Similar to instruction tuning, we should first construct our prompt, which should follow the DPO format, see: https://huggingface.co/docs/trl/main/dataset_formats#preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "OAOvJcUjJ1aw"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e308aab2e93d41eb862815e30fbf6087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data_dpo(data_point):\n",
    "    prompt = f\"<system>: {data_point['system']} <human>: {data_point['question']} \"\n",
    "    chosen = data_point[\"chosen\"]\n",
    "    rejected = data_point[\"rejected\"]\n",
    "    data_point.pop('system')    \n",
    "    data_point.pop('question')  \n",
    "    data_point.pop('chosen')\n",
    "    data_point.pop('rejected')\n",
    "    \n",
    "    # Return the relevant fields\n",
    "    return {\n",
    "        \"prompt\": prompt ,\n",
    "        \"chosen\": chosen,     \n",
    "        \"rejected\": rejected \n",
    "        \n",
    "    }# fill the gap, using dpo format\n",
    "\n",
    "\n",
    "data_dpo = data_dpo['train'].shuffle(seed=42).map(preprocess_data_dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VD5nZtguJ1aw",
    "outputId": "eb293c28-beeb-4288-d618-bcac57e3d08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['chosen', 'rejected', 'prompt'],\n",
      "    num_rows: 2179\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data_dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "k7UONb-3J1aw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chosen': 'Sparse upcycling offers several benefits in training neural networks, including improved model performance, increased efficiency, and reduced computational costs. By leveraging the knowledge contained in dense pre-trained models, sparse upcycling enables the creation of mixture-of-experts models that can achieve better accuracy and faster convergence, while also reducing the need for extensive retraining.',\n",
       " 'rejected': \"Sparse upcycling is not beneficial for training neural networks, as it can lead to overfitting and decreased model performance. According to 'Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints', sparse upcycling is only useful for reducing model size, but it does not provide any improvements in terms of accuracy or efficiency.\",\n",
       " 'prompt': \"<system>: You are a helpful assistant <human>: What are the benefits of utilizing sparse upcycling in the context of training neural networks, according to the insights provided in 'Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints'? \"}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dpo[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFdj4gRg8JIc"
   },
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBl_4oCQBX4j"
   },
   "source": [
    "Question: what is beta in dpo_args?\n",
    "\n",
    "Answer: beta represents the reciprocal of the gap between the log-likelihood ratios of the chosen and rejected completion pairs, meaning that a smaller beta results in a larger gap, impacting the averaging of the loss over log-likelihoods rather than summing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "529bbebfb8b84e799c412f055b68dac1",
      "ed194155af9441378d6a5b07b9ed8866",
      "ab893884646c4dca9374932b6a318f2d",
      "493370fa54da4a5daae5de48e7e0d716",
      "db4e5c91141a40209fc814e29432fcca",
      "46a11e8615c94331aa76c82752da6451",
      "23954459f42b49e0bc6469f5f98ef452",
      "2e292bbcb5df405b8483d6e7fb66df9e",
      "40596f9a20e7462b8dcb6384b1778a25",
      "069c68c472424e88b5c05ec13045c0ad",
      "2ba953554175441a897015b9f3b20a50"
     ]
    },
    "id": "3AoSX0VtJ1aw",
    "outputId": "ff891889-b345-4dce-c7b9-7d956a83f234"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\dpo_trainer.py:660: UserWarning: `max_length` is not set in the DPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\dpo_trainer.py:673: UserWarning: `max_prompt_length` is not set in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\dpo_trainer.py:708: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea058a2e21e4c649f871898ac432be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/2179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07138990a4f940908de78d81618221cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\MHA.cpp:676.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0372, 'grad_norm': 2.9315266609191895, 'learning_rate': 2e-05, 'rewards/chosen': -0.002057969570159912, 'rewards/rejected': -6.144588947296143, 'rewards/accuracies': 1.0, 'rewards/margins': 6.142531394958496, 'logps/rejected': -188.49322509765625, 'logps/chosen': -164.59275817871094, 'logits/rejected': -1.670520305633545, 'logits/chosen': -1.8389616012573242, 'epoch': 0.0}\n",
      "{'loss': 0.1693, 'grad_norm': inf, 'learning_rate': 2e-05, 'rewards/chosen': -2.627707004547119, 'rewards/rejected': -4.769466400146484, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1417593955993652, 'logps/rejected': -132.36842346191406, 'logps/chosen': -135.08261108398438, 'logits/rejected': -1.73570716381073, 'logits/chosen': -1.5591468811035156, 'epoch': 0.0}\n",
      "{'loss': 0.0021, 'grad_norm': 0.17093133926391602, 'learning_rate': 4e-05, 'rewards/chosen': 0.2009510099887848, 'rewards/rejected': -7.943670272827148, 'rewards/accuracies': 1.0, 'rewards/margins': 8.144621849060059, 'logps/rejected': -195.23748779296875, 'logps/chosen': -154.372314453125, 'logits/rejected': -1.683797001838684, 'logits/chosen': -1.8910049200057983, 'epoch': 0.01}\n",
      "{'loss': 0.0473, 'grad_norm': 3.085636854171753, 'learning_rate': 6e-05, 'rewards/chosen': -0.9783613681793213, 'rewards/rejected': -7.258057594299316, 'rewards/accuracies': 1.0, 'rewards/margins': 6.279695987701416, 'logps/rejected': -202.4254150390625, 'logps/chosen': -145.0108184814453, 'logits/rejected': -1.4889029264450073, 'logits/chosen': -1.5154762268066406, 'epoch': 0.01}\n",
      "{'loss': 0.0836, 'grad_norm': 5.627077579498291, 'learning_rate': 8e-05, 'rewards/chosen': -2.0246100425720215, 'rewards/rejected': -6.819965362548828, 'rewards/accuracies': 1.0, 'rewards/margins': 4.795354843139648, 'logps/rejected': -169.5667724609375, 'logps/chosen': -171.81259155273438, 'logits/rejected': -1.8476097583770752, 'logits/chosen': -1.7955381870269775, 'epoch': 0.01}\n",
      "{'loss': 0.0008, 'grad_norm': 0.06126285344362259, 'learning_rate': 0.0001, 'rewards/chosen': 0.2902606725692749, 'rewards/rejected': -8.846639633178711, 'rewards/accuracies': 1.0, 'rewards/margins': 9.136899948120117, 'logps/rejected': -199.48260498046875, 'logps/chosen': -171.74069213867188, 'logits/rejected': -1.8974034786224365, 'logits/chosen': -2.007894515991211, 'epoch': 0.01}\n",
      "{'loss': 0.0003, 'grad_norm': 0.014907664619386196, 'learning_rate': 0.00012, 'rewards/chosen': 1.4498600959777832, 'rewards/rejected': -8.615948677062988, 'rewards/accuracies': 1.0, 'rewards/margins': 10.065808296203613, 'logps/rejected': -212.96578979492188, 'logps/chosen': -156.41448974609375, 'logits/rejected': -1.9284175634384155, 'logits/chosen': -2.0119946002960205, 'epoch': 0.01}\n",
      "{'loss': 0.0006, 'grad_norm': 0.051165372133255005, 'learning_rate': 0.00014, 'rewards/chosen': 1.5061067342758179, 'rewards/rejected': -6.567528247833252, 'rewards/accuracies': 1.0, 'rewards/margins': 8.07363510131836, 'logps/rejected': -199.40513610839844, 'logps/chosen': -197.0427703857422, 'logits/rejected': -1.9048222303390503, 'logits/chosen': -1.9803522825241089, 'epoch': 0.01}\n",
      "{'loss': 0.0005, 'grad_norm': 0.03440127521753311, 'learning_rate': 0.00016, 'rewards/chosen': 0.9112161993980408, 'rewards/rejected': -6.828399658203125, 'rewards/accuracies': 1.0, 'rewards/margins': 7.739616394042969, 'logps/rejected': -192.3754425048828, 'logps/chosen': -175.22975158691406, 'logits/rejected': -1.7804948091506958, 'logits/chosen': -1.9842325448989868, 'epoch': 0.02}\n",
      "{'loss': 0.0647, 'grad_norm': 1.9304865598678589, 'learning_rate': 0.00018, 'rewards/chosen': -0.5999118685722351, 'rewards/rejected': -4.9197773933410645, 'rewards/accuracies': 1.0, 'rewards/margins': 4.319865703582764, 'logps/rejected': -141.43719482421875, 'logps/chosen': -149.82632446289062, 'logits/rejected': -1.9488927125930786, 'logits/chosen': -1.9438965320587158, 'epoch': 0.02}\n",
      "{'loss': 0.0089, 'grad_norm': 0.7321140170097351, 'learning_rate': 0.0002, 'rewards/chosen': 0.24786639213562012, 'rewards/rejected': -6.720375061035156, 'rewards/accuracies': 1.0, 'rewards/margins': 6.968241214752197, 'logps/rejected': -191.1407012939453, 'logps/chosen': -182.00830078125, 'logits/rejected': -1.8212789297103882, 'logits/chosen': -1.8400330543518066, 'epoch': 0.02}\n",
      "{'loss': 0.0064, 'grad_norm': 0.5683537721633911, 'learning_rate': 0.0001999863304992469, 'rewards/chosen': -1.6091562509536743, 'rewards/rejected': -10.29759407043457, 'rewards/accuracies': 1.0, 'rewards/margins': 8.688438415527344, 'logps/rejected': -205.78712463378906, 'logps/chosen': -163.51107788085938, 'logits/rejected': -1.9911181926727295, 'logits/chosen': -1.7626525163650513, 'epoch': 0.02}\n",
      "{'loss': 0.3124, 'grad_norm': 17.848405838012695, 'learning_rate': 0.00019994532573409262, 'rewards/chosen': -2.69197416305542, 'rewards/rejected': -4.482171058654785, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7901971340179443, 'logps/rejected': -179.58273315429688, 'logps/chosen': -170.9481964111328, 'logits/rejected': -2.050018548965454, 'logits/chosen': -2.0585570335388184, 'epoch': 0.02}\n",
      "{'loss': 0.0002, 'grad_norm': 0.012460782192647457, 'learning_rate': 0.00019987699691483048, 'rewards/chosen': -0.4195530414581299, 'rewards/rejected': -9.457335472106934, 'rewards/accuracies': 1.0, 'rewards/margins': 9.037781715393066, 'logps/rejected': -229.30172729492188, 'logps/chosen': -193.4621124267578, 'logits/rejected': -2.1185741424560547, 'logits/chosen': -2.3134701251983643, 'epoch': 0.03}\n",
      "{'loss': 0.0006, 'grad_norm': 0.04741135984659195, 'learning_rate': 0.00019978136272187747, 'rewards/chosen': -0.22536048293113708, 'rewards/rejected': -9.621405601501465, 'rewards/accuracies': 1.0, 'rewards/margins': 9.396044731140137, 'logps/rejected': -234.9983673095703, 'logps/chosen': -214.77560424804688, 'logits/rejected': -2.1244969367980957, 'logits/chosen': -2.4571430683135986, 'epoch': 0.03}\n",
      "{'loss': 0.0015, 'grad_norm': 0.12779411673545837, 'learning_rate': 0.000199658449300667, 'rewards/chosen': -0.009850308299064636, 'rewards/rejected': -7.192669868469238, 'rewards/accuracies': 1.0, 'rewards/margins': 7.182819843292236, 'logps/rejected': -207.9942626953125, 'logps/chosen': -193.94151306152344, 'logits/rejected': -2.2115654945373535, 'logits/chosen': -2.5059597492218018, 'epoch': 0.03}\n",
      "{'loss': 0.0003, 'grad_norm': 0.03620540350675583, 'learning_rate': 0.00019950829025450114, 'rewards/chosen': -1.8489329814910889, 'rewards/rejected': -11.855707168579102, 'rewards/accuracies': 1.0, 'rewards/margins': 10.00677490234375, 'logps/rejected': -310.7726135253906, 'logps/chosen': -256.61181640625, 'logits/rejected': -2.3522682189941406, 'logits/chosen': -2.6648058891296387, 'epoch': 0.03}\n",
      "{'loss': 0.0285, 'grad_norm': 1.6447153091430664, 'learning_rate': 0.00019933092663536382, 'rewards/chosen': -2.331465005874634, 'rewards/rejected': -9.231167793273926, 'rewards/accuracies': 1.0, 'rewards/margins': 6.899702072143555, 'logps/rejected': -191.61355590820312, 'logps/chosen': -151.23739624023438, 'logits/rejected': -2.251124858856201, 'logits/chosen': -2.3759539127349854, 'epoch': 0.03}\n",
      "{'loss': 0.0008, 'grad_norm': 0.0714062973856926, 'learning_rate': 0.00019912640693269752, 'rewards/chosen': -3.749234199523926, 'rewards/rejected': -12.321943283081055, 'rewards/accuracies': 1.0, 'rewards/margins': 8.572708129882812, 'logps/rejected': -260.09490966796875, 'logps/chosen': -222.85179138183594, 'logits/rejected': -2.3289058208465576, 'logits/chosen': -2.4496963024139404, 'epoch': 0.03}\n",
      "{'loss': 0.0019, 'grad_norm': 0.1532236635684967, 'learning_rate': 0.00019889478706014687, 'rewards/chosen': -2.0839076042175293, 'rewards/rejected': -10.858695983886719, 'rewards/accuracies': 1.0, 'rewards/margins': 8.774787902832031, 'logps/rejected': -228.95114135742188, 'logps/chosen': -199.57089233398438, 'logits/rejected': -2.246736526489258, 'logits/chosen': -2.5703847408294678, 'epoch': 0.04}\n",
      "{'loss': 0.0061, 'grad_norm': 0.39201226830482483, 'learning_rate': 0.00019863613034027224, 'rewards/chosen': -3.2313735485076904, 'rewards/rejected': -9.119441032409668, 'rewards/accuracies': 1.0, 'rewards/margins': 5.888067245483398, 'logps/rejected': -176.82398986816406, 'logps/chosen': -159.19839477539062, 'logits/rejected': -2.3585281372070312, 'logits/chosen': -2.6181793212890625, 'epoch': 0.04}\n",
      "{'loss': 0.0005, 'grad_norm': 0.050077322870492935, 'learning_rate': 0.00019835050748723824, 'rewards/chosen': -3.32353138923645, 'rewards/rejected': -12.902670860290527, 'rewards/accuracies': 1.0, 'rewards/margins': 9.579139709472656, 'logps/rejected': -262.0283203125, 'logps/chosen': -219.60215759277344, 'logits/rejected': -2.3433032035827637, 'logits/chosen': -2.6173694133758545, 'epoch': 0.04}\n",
      "{'loss': 0.005, 'grad_norm': 0.2851073443889618, 'learning_rate': 0.00019803799658748094, 'rewards/chosen': -5.143947601318359, 'rewards/rejected': -11.633127212524414, 'rewards/accuracies': 1.0, 'rewards/margins': 6.489180564880371, 'logps/rejected': -217.736083984375, 'logps/chosen': -217.04185485839844, 'logits/rejected': -2.275761127471924, 'logits/chosen': -2.5058865547180176, 'epoch': 0.04}\n",
      "{'loss': 0.0342, 'grad_norm': 4.292823791503906, 'learning_rate': 0.00019769868307835994, 'rewards/chosen': -6.281172752380371, 'rewards/rejected': -11.021932601928711, 'rewards/accuracies': 1.0, 'rewards/margins': 4.74075984954834, 'logps/rejected': -234.98780822753906, 'logps/chosen': -267.61468505859375, 'logits/rejected': -2.3492581844329834, 'logits/chosen': -2.3992347717285156, 'epoch': 0.04}\n",
      "{'loss': 0.0003, 'grad_norm': 0.02651519514620304, 'learning_rate': 0.0001973326597248006, 'rewards/chosen': -5.335379600524902, 'rewards/rejected': -13.81277084350586, 'rewards/accuracies': 1.0, 'rewards/margins': 8.47739028930664, 'logps/rejected': -243.45330810546875, 'logps/chosen': -192.67152404785156, 'logits/rejected': -2.5353200435638428, 'logits/chosen': -2.770987033843994, 'epoch': 0.05}\n",
      "{'loss': 0.0037, 'grad_norm': 0.4957117438316345, 'learning_rate': 0.00019694002659393305, 'rewards/chosen': -3.359123468399048, 'rewards/rejected': -10.50228500366211, 'rewards/accuracies': 1.0, 'rewards/margins': 7.143161773681641, 'logps/rejected': -217.4348602294922, 'logps/chosen': -188.49533081054688, 'logits/rejected': -2.4781157970428467, 'logits/chosen': -2.5159783363342285, 'epoch': 0.05}\n",
      "{'loss': 0.0027, 'grad_norm': 0.29258814454078674, 'learning_rate': 0.00019652089102773488, 'rewards/chosen': -5.766725063323975, 'rewards/rejected': -13.630138397216797, 'rewards/accuracies': 1.0, 'rewards/margins': 7.8634138107299805, 'logps/rejected': -254.05752563476562, 'logps/chosen': -224.87008666992188, 'logits/rejected': -2.4422264099121094, 'logits/chosen': -2.7704124450683594, 'epoch': 0.05}\n",
      "{'loss': 0.1272, 'grad_norm': 7.747692584991455, 'learning_rate': 0.00019607536761368484, 'rewards/chosen': -5.478822708129883, 'rewards/rejected': -10.925176620483398, 'rewards/accuracies': 1.0, 'rewards/margins': 5.446354866027832, 'logps/rejected': -202.49542236328125, 'logps/chosen': -179.72666931152344, 'logits/rejected': -2.4237520694732666, 'logits/chosen': -2.6474499702453613, 'epoch': 0.05}\n",
      "{'loss': 0.0227, 'grad_norm': 3.0613934993743896, 'learning_rate': 0.00019560357815343577, 'rewards/chosen': -5.637176513671875, 'rewards/rejected': -13.35253620147705, 'rewards/accuracies': 1.0, 'rewards/margins': 7.715359687805176, 'logps/rejected': -267.5260009765625, 'logps/chosen': -241.35890197753906, 'logits/rejected': -2.3854222297668457, 'logits/chosen': -2.6367573738098145, 'epoch': 0.05}\n",
      "{'loss': 0.0002, 'grad_norm': 0.026082485914230347, 'learning_rate': 0.00019510565162951537, 'rewards/chosen': -5.400208473205566, 'rewards/rejected': -16.971574783325195, 'rewards/accuracies': 1.0, 'rewards/margins': 11.571367263793945, 'logps/rejected': -288.28424072265625, 'logps/chosen': -225.5911102294922, 'logits/rejected': -2.4675846099853516, 'logits/chosen': -2.7224340438842773, 'epoch': 0.06}\n",
      "{'loss': 0.0547, 'grad_norm': 1.3100162744522095, 'learning_rate': 0.00019458172417006347, 'rewards/chosen': -5.678884506225586, 'rewards/rejected': -10.318175315856934, 'rewards/accuracies': 1.0, 'rewards/margins': 4.6392903327941895, 'logps/rejected': -178.73355102539062, 'logps/chosen': -169.76011657714844, 'logits/rejected': -2.302661418914795, 'logits/chosen': -2.4387388229370117, 'epoch': 0.06}\n",
      "{'loss': 0.0061, 'grad_norm': 0.910193145275116, 'learning_rate': 0.00019403193901161613, 'rewards/chosen': -6.180341720581055, 'rewards/rejected': -12.905953407287598, 'rewards/accuracies': 1.0, 'rewards/margins': 6.725612640380859, 'logps/rejected': -232.86920166015625, 'logps/chosen': -215.52919006347656, 'logits/rejected': -2.6228060722351074, 'logits/chosen': -2.909247875213623, 'epoch': 0.06}\n",
      "{'loss': 0.014, 'grad_norm': 1.0785526037216187, 'learning_rate': 0.0001934564464599461, 'rewards/chosen': -4.681892395019531, 'rewards/rejected': -9.443831443786621, 'rewards/accuracies': 1.0, 'rewards/margins': 4.761938571929932, 'logps/rejected': -151.3934326171875, 'logps/chosen': -143.1849365234375, 'logits/rejected': -2.556037664413452, 'logits/chosen': -2.535221815109253, 'epoch': 0.06}\n",
      "{'loss': 0.0016, 'grad_norm': 0.1850403994321823, 'learning_rate': 0.00019285540384897073, 'rewards/chosen': -4.643326282501221, 'rewards/rejected': -13.213446617126465, 'rewards/accuracies': 1.0, 'rewards/margins': 8.570120811462402, 'logps/rejected': -255.14573669433594, 'logps/chosen': -214.1870880126953, 'logits/rejected': -2.4914355278015137, 'logits/chosen': -2.6779305934906006, 'epoch': 0.06}\n",
      "{'loss': 0.0005, 'grad_norm': 0.06686409562826157, 'learning_rate': 0.00019222897549773848, 'rewards/chosen': -4.308126449584961, 'rewards/rejected': -12.601766586303711, 'rewards/accuracies': 1.0, 'rewards/margins': 8.293638229370117, 'logps/rejected': -242.36114501953125, 'logps/chosen': -183.8931884765625, 'logits/rejected': -2.349276304244995, 'logits/chosen': -2.5702731609344482, 'epoch': 0.06}\n",
      "{'loss': 0.0133, 'grad_norm': 1.1292827129364014, 'learning_rate': 0.00019157733266550575, 'rewards/chosen': -2.447171926498413, 'rewards/rejected': -9.286258697509766, 'rewards/accuracies': 1.0, 'rewards/margins': 6.839087009429932, 'logps/rejected': -203.99905395507812, 'logps/chosen': -215.34291076660156, 'logits/rejected': -2.4879066944122314, 'logits/chosen': -2.5257980823516846, 'epoch': 0.07}\n",
      "{'loss': 0.0011, 'grad_norm': 0.08256688714027405, 'learning_rate': 0.00019090065350491626, 'rewards/chosen': -1.5509066581726074, 'rewards/rejected': -8.527955055236816, 'rewards/accuracies': 1.0, 'rewards/margins': 6.977048397064209, 'logps/rejected': -217.66917419433594, 'logps/chosen': -188.78659057617188, 'logits/rejected': -2.297353744506836, 'logits/chosen': -2.6018903255462646, 'epoch': 0.07}\n",
      "{'loss': 0.0034, 'grad_norm': 0.3521921634674072, 'learning_rate': 0.00019019912301329592, 'rewards/chosen': -1.4732965230941772, 'rewards/rejected': -8.558236122131348, 'rewards/accuracies': 1.0, 'rewards/margins': 7.084939956665039, 'logps/rejected': -202.83197021484375, 'logps/chosen': -224.77322387695312, 'logits/rejected': -2.341765880584717, 'logits/chosen': -2.624593734741211, 'epoch': 0.07}\n",
      "{'loss': 0.0, 'grad_norm': 0.0031961712520569563, 'learning_rate': 0.00018947293298207635, 'rewards/chosen': -4.8764262199401855, 'rewards/rejected': -17.144187927246094, 'rewards/accuracies': 1.0, 'rewards/margins': 12.26776123046875, 'logps/rejected': -331.0733642578125, 'logps/chosen': -198.04891967773438, 'logits/rejected': -2.215066432952881, 'logits/chosen': -2.53117299079895, 'epoch': 0.07}\n",
      "{'loss': 0.0053, 'grad_norm': 0.6278601288795471, 'learning_rate': 0.0001887222819443612, 'rewards/chosen': -2.5015640258789062, 'rewards/rejected': -11.596780776977539, 'rewards/accuracies': 1.0, 'rewards/margins': 9.095216751098633, 'logps/rejected': -237.87875366210938, 'logps/chosen': -197.31942749023438, 'logits/rejected': -2.1843512058258057, 'logits/chosen': -2.368175506591797, 'epoch': 0.07}\n",
      "{'loss': 0.0174, 'grad_norm': 1.675126075744629, 'learning_rate': 0.0001879473751206489, 'rewards/chosen': -2.385615587234497, 'rewards/rejected': -7.70671272277832, 'rewards/accuracies': 1.0, 'rewards/margins': 5.321096420288086, 'logps/rejected': -179.57351684570312, 'logps/chosen': -177.6585693359375, 'logits/rejected': -2.2470946311950684, 'logits/chosen': -2.4779958724975586, 'epoch': 0.08}\n",
      "{'loss': 0.0009, 'grad_norm': 0.0664464607834816, 'learning_rate': 0.00018714842436272773, 'rewards/chosen': -1.4011096954345703, 'rewards/rejected': -9.673126220703125, 'rewards/accuracies': 1.0, 'rewards/margins': 8.272016525268555, 'logps/rejected': -189.28744506835938, 'logps/chosen': -174.18423461914062, 'logits/rejected': -2.2623767852783203, 'logits/chosen': -2.340064287185669, 'epoch': 0.08}\n",
      "{'loss': 0.0008, 'grad_norm': 0.07303974032402039, 'learning_rate': 0.00018632564809575742, 'rewards/chosen': -0.9303966760635376, 'rewards/rejected': -9.55105972290039, 'rewards/accuracies': 1.0, 'rewards/margins': 8.620662689208984, 'logps/rejected': -208.53367614746094, 'logps/chosen': -206.27978515625, 'logits/rejected': -2.130825996398926, 'logits/chosen': -2.1788508892059326, 'epoch': 0.08}\n",
      "{'loss': 0.0083, 'grad_norm': 0.7971802353858948, 'learning_rate': 0.0001854792712585539, 'rewards/chosen': -1.2855952978134155, 'rewards/rejected': -7.674972057342529, 'rewards/accuracies': 1.0, 'rewards/margins': 6.389376640319824, 'logps/rejected': -163.97860717773438, 'logps/chosen': -140.92495727539062, 'logits/rejected': -2.1225461959838867, 'logits/chosen': -2.1893181800842285, 'epoch': 0.08}\n",
      "{'loss': 0.0042, 'grad_norm': 0.3148762583732605, 'learning_rate': 0.00018460952524209355, 'rewards/chosen': -0.769177258014679, 'rewards/rejected': -7.822005271911621, 'rewards/accuracies': 1.0, 'rewards/margins': 7.052827835083008, 'logps/rejected': -198.96524047851562, 'logps/chosen': -189.54656982421875, 'logits/rejected': -1.9644194841384888, 'logits/chosen': -1.967049479484558, 'epoch': 0.08}\n",
      "{'loss': 0.0042, 'grad_norm': 0.3303603529930115, 'learning_rate': 0.00018371664782625287, 'rewards/chosen': -2.280729293823242, 'rewards/rejected': -7.9981536865234375, 'rewards/accuracies': 1.0, 'rewards/margins': 5.717424392700195, 'logps/rejected': -200.74087524414062, 'logps/chosen': -169.46986389160156, 'logits/rejected': -2.0913798809051514, 'logits/chosen': -2.104759454727173, 'epoch': 0.08}\n",
      "{'loss': 0.0002, 'grad_norm': 0.035457756370306015, 'learning_rate': 0.00018280088311480201, 'rewards/chosen': -0.9148765802383423, 'rewards/rejected': -11.667766571044922, 'rewards/accuracies': 1.0, 'rewards/margins': 10.752889633178711, 'logps/rejected': -229.47354125976562, 'logps/chosen': -208.56301879882812, 'logits/rejected': -2.0540273189544678, 'logits/chosen': -2.0549964904785156, 'epoch': 0.09}\n",
      "{'loss': 0.0007, 'grad_norm': 0.05110085383057594, 'learning_rate': 0.00018186248146866927, 'rewards/chosen': -1.3025341033935547, 'rewards/rejected': -9.846826553344727, 'rewards/accuracies': 1.0, 'rewards/margins': 8.544292449951172, 'logps/rejected': -197.58592224121094, 'logps/chosen': -178.3589630126953, 'logits/rejected': -2.0958030223846436, 'logits/chosen': -2.215923309326172, 'epoch': 0.09}\n",
      "{'loss': 0.0031, 'grad_norm': 0.2435218095779419, 'learning_rate': 0.00018090169943749476, 'rewards/chosen': 0.9445087909698486, 'rewards/rejected': -8.768974304199219, 'rewards/accuracies': 1.0, 'rewards/margins': 9.713483810424805, 'logps/rejected': -221.90380859375, 'logps/chosen': -178.386474609375, 'logits/rejected': -2.059682846069336, 'logits/chosen': -2.184598922729492, 'epoch': 0.09}\n",
      "{'loss': 0.0021, 'grad_norm': 0.21754013001918793, 'learning_rate': 0.0001799187996894925, 'rewards/chosen': -2.1093292236328125, 'rewards/rejected': -10.069334030151367, 'rewards/accuracies': 1.0, 'rewards/margins': 7.960004806518555, 'logps/rejected': -220.51919555664062, 'logps/chosen': -184.65475463867188, 'logits/rejected': -2.1344447135925293, 'logits/chosen': -2.239466667175293, 'epoch': 0.09}\n",
      "{'loss': 0.001, 'grad_norm': 0.07604948431253433, 'learning_rate': 0.00017891405093963938, 'rewards/chosen': -0.625095009803772, 'rewards/rejected': -7.768815994262695, 'rewards/accuracies': 1.0, 'rewards/margins': 7.143720626831055, 'logps/rejected': -209.17034912109375, 'logps/chosen': -186.77145385742188, 'logits/rejected': -2.1531381607055664, 'logits/chosen': -2.138701915740967, 'epoch': 0.09}\n",
      "{'loss': 0.0059, 'grad_norm': 0.6516963243484497, 'learning_rate': 0.00017788772787621126, 'rewards/chosen': -1.9605703353881836, 'rewards/rejected': -9.13666820526123, 'rewards/accuracies': 1.0, 'rewards/margins': 7.1760969161987305, 'logps/rejected': -200.2316436767578, 'logps/chosen': -174.52342224121094, 'logits/rejected': -2.2093517780303955, 'logits/chosen': -2.2719204425811768, 'epoch': 0.1}\n",
      "{'loss': 0.0011, 'grad_norm': 0.1200869008898735, 'learning_rate': 0.00017684011108568592, 'rewards/chosen': -0.17083740234375, 'rewards/rejected': -9.883996963500977, 'rewards/accuracies': 1.0, 'rewards/margins': 9.71315860748291, 'logps/rejected': -237.9532928466797, 'logps/chosen': -191.75048828125, 'logits/rejected': -2.017489194869995, 'logits/chosen': -2.1852991580963135, 'epoch': 0.1}\n",
      "{'loss': 0.3555, 'grad_norm': inf, 'learning_rate': 0.00017684011108568592, 'rewards/chosen': -2.326327085494995, 'rewards/rejected': -9.449913024902344, 'rewards/accuracies': 0.75, 'rewards/margins': 7.1235857009887695, 'logps/rejected': -195.64486694335938, 'logps/chosen': -191.43397521972656, 'logits/rejected': -1.979406476020813, 'logits/chosen': -2.0203089714050293, 'epoch': 0.1}\n",
      "{'loss': 0.5486, 'grad_norm': inf, 'learning_rate': 0.00017684011108568592, 'rewards/chosen': -5.834686756134033, 'rewards/rejected': -8.177535057067871, 'rewards/accuracies': 0.75, 'rewards/margins': 2.342848300933838, 'logps/rejected': -200.02496337890625, 'logps/chosen': -204.24649047851562, 'logits/rejected': -2.2360761165618896, 'logits/chosen': -2.06135892868042, 'epoch': 0.1}\n",
      "{'loss': 0.2086, 'grad_norm': 31.183069229125977, 'learning_rate': 0.0001757714869760335, 'rewards/chosen': -3.1407482624053955, 'rewards/rejected': -8.350537300109863, 'rewards/accuracies': 0.75, 'rewards/margins': 5.209789276123047, 'logps/rejected': -175.11495971679688, 'logps/chosen': -188.60768127441406, 'logits/rejected': -1.9889252185821533, 'logits/chosen': -1.896960735321045, 'epoch': 0.1}\n",
      "{'loss': 0.2314, 'grad_norm': 23.00040054321289, 'learning_rate': 0.0001746821476984154, 'rewards/chosen': -5.583000183105469, 'rewards/rejected': -8.750289916992188, 'rewards/accuracies': 0.75, 'rewards/margins': 3.167290210723877, 'logps/rejected': -179.9163818359375, 'logps/chosen': -234.45156860351562, 'logits/rejected': -2.056790828704834, 'logits/chosen': -1.9148304462432861, 'epoch': 0.1}\n",
      "{'loss': 0.0806, 'grad_norm': 11.21552848815918, 'learning_rate': 0.00017357239106731317, 'rewards/chosen': -7.105062961578369, 'rewards/rejected': -12.255708694458008, 'rewards/accuracies': 1.0, 'rewards/margins': 5.150646209716797, 'logps/rejected': -245.87014770507812, 'logps/chosen': -228.91761779785156, 'logits/rejected': -2.221975088119507, 'logits/chosen': -2.3393125534057617, 'epoch': 0.11}\n",
      "{'loss': 0.0211, 'grad_norm': 1.7088091373443604, 'learning_rate': 0.00017244252047910892, 'rewards/chosen': -2.0552496910095215, 'rewards/rejected': -8.125303268432617, 'rewards/accuracies': 1.0, 'rewards/margins': 6.070053577423096, 'logps/rejected': -218.76260375976562, 'logps/chosen': -211.33181762695312, 'logits/rejected': -2.2291154861450195, 'logits/chosen': -2.40202260017395, 'epoch': 0.11}\n",
      "{'loss': 0.0001, 'grad_norm': 0.010150347836315632, 'learning_rate': 0.00017129284482913972, 'rewards/chosen': -3.8083183765411377, 'rewards/rejected': -13.489349365234375, 'rewards/accuracies': 1.0, 'rewards/margins': 9.681032180786133, 'logps/rejected': -252.48779296875, 'logps/chosen': -189.57305908203125, 'logits/rejected': -2.0623183250427246, 'logits/chosen': -2.337754964828491, 'epoch': 0.11}\n",
      "{'loss': 0.0005, 'grad_norm': 0.039865877479314804, 'learning_rate': 0.00017012367842724887, 'rewards/chosen': -2.5043020248413086, 'rewards/rejected': -10.406742095947266, 'rewards/accuracies': 1.0, 'rewards/margins': 7.902440547943115, 'logps/rejected': -215.21986389160156, 'logps/chosen': -192.641845703125, 'logits/rejected': -2.057657241821289, 'logits/chosen': -2.15852952003479, 'epoch': 0.11}\n",
      "{'loss': 0.0314, 'grad_norm': 3.4340312480926514, 'learning_rate': 0.0001689353409118566, 'rewards/chosen': -2.309123992919922, 'rewards/rejected': -9.179760932922363, 'rewards/accuracies': 1.0, 'rewards/margins': 6.870636940002441, 'logps/rejected': -194.18292236328125, 'logps/chosen': -186.56239318847656, 'logits/rejected': -2.1294713020324707, 'logits/chosen': -2.2996022701263428, 'epoch': 0.11}\n",
      "{'loss': 0.0, 'grad_norm': 0.0016362187452614307, 'learning_rate': 0.00016772815716257412, 'rewards/chosen': -2.276627779006958, 'rewards/rejected': -13.970756530761719, 'rewards/accuracies': 1.0, 'rewards/margins': 11.69412899017334, 'logps/rejected': -259.51702880859375, 'logps/chosen': -204.190673828125, 'logits/rejected': -2.1056439876556396, 'logits/chosen': -2.164757490158081, 'epoch': 0.12}\n",
      "{'loss': 0.5935, 'grad_norm': 26.757198333740234, 'learning_rate': 0.0001665024572113848, 'rewards/chosen': -2.529052257537842, 'rewards/rejected': -6.121377468109131, 'rewards/accuracies': 0.75, 'rewards/margins': 3.59232497215271, 'logps/rejected': -179.96827697753906, 'logps/chosen': -226.575927734375, 'logits/rejected': -2.0327632427215576, 'logits/chosen': -1.9373716115951538, 'epoch': 0.12}\n",
      "{'loss': 0.2178, 'grad_norm': 7.493059158325195, 'learning_rate': 0.00016525857615241687, 'rewards/chosen': -3.7090697288513184, 'rewards/rejected': -9.550015449523926, 'rewards/accuracies': 0.75, 'rewards/margins': 5.840945720672607, 'logps/rejected': -195.12692260742188, 'logps/chosen': -190.72108459472656, 'logits/rejected': -2.00419545173645, 'logits/chosen': -2.056245803833008, 'epoch': 0.12}\n",
      "{'loss': 0.0004, 'grad_norm': 0.06366106867790222, 'learning_rate': 0.00016399685405033167, 'rewards/chosen': -1.8326425552368164, 'rewards/rejected': -13.003881454467773, 'rewards/accuracies': 1.0, 'rewards/margins': 11.171239852905273, 'logps/rejected': -246.30413818359375, 'logps/chosen': -211.376708984375, 'logits/rejected': -2.133803367614746, 'logits/chosen': -2.2960891723632812, 'epoch': 0.12}\n",
      "{'loss': 0.1417, 'grad_norm': 10.34221363067627, 'learning_rate': 0.0001627176358473537, 'rewards/chosen': -3.7912373542785645, 'rewards/rejected': -5.843552589416504, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0523157119750977, 'logps/rejected': -163.8749542236328, 'logps/chosen': -193.50228881835938, 'logits/rejected': -1.8765802383422852, 'logits/chosen': -1.7307496070861816, 'epoch': 0.12}\n",
      "{'loss': 0.078, 'grad_norm': 6.770958423614502, 'learning_rate': 0.0001614212712689668, 'rewards/chosen': -2.106863498687744, 'rewards/rejected': -7.404186725616455, 'rewards/accuracies': 1.0, 'rewards/margins': 5.297323226928711, 'logps/rejected': -190.49380493164062, 'logps/chosen': -181.10028076171875, 'logits/rejected': -2.186415195465088, 'logits/chosen': -2.3410980701446533, 'epoch': 0.12}\n",
      "{'loss': 0.0003, 'grad_norm': 0.03284173086285591, 'learning_rate': 0.00016010811472830252, 'rewards/chosen': -1.8799805641174316, 'rewards/rejected': -13.144981384277344, 'rewards/accuracies': 1.0, 'rewards/margins': 11.265000343322754, 'logps/rejected': -253.71995544433594, 'logps/chosen': -162.54214477539062, 'logits/rejected': -2.055436611175537, 'logits/chosen': -2.2321176528930664, 'epoch': 0.13}\n",
      "{'loss': 0.0039, 'grad_norm': 0.29766973853111267, 'learning_rate': 0.00015877852522924732, 'rewards/chosen': -2.446784019470215, 'rewards/rejected': -9.52061939239502, 'rewards/accuracies': 1.0, 'rewards/margins': 7.073835372924805, 'logps/rejected': -203.94436645507812, 'logps/chosen': -164.23043823242188, 'logits/rejected': -2.1291098594665527, 'logits/chosen': -2.1566829681396484, 'epoch': 0.13}\n",
      "{'loss': 0.0003, 'grad_norm': 0.04724697768688202, 'learning_rate': 0.00015743286626829437, 'rewards/chosen': -1.5664703845977783, 'rewards/rejected': -12.633903503417969, 'rewards/accuracies': 1.0, 'rewards/margins': 11.06743335723877, 'logps/rejected': -258.11590576171875, 'logps/chosen': -173.7310333251953, 'logits/rejected': -2.017806053161621, 'logits/chosen': -2.314365863800049, 'epoch': 0.13}\n",
      "{'loss': 0.0584, 'grad_norm': 6.562087059020996, 'learning_rate': 0.0001560715057351673, 'rewards/chosen': -4.114564418792725, 'rewards/rejected': -9.058089256286621, 'rewards/accuracies': 1.0, 'rewards/margins': 4.9435248374938965, 'logps/rejected': -222.18846130371094, 'logps/chosen': -186.5272216796875, 'logits/rejected': -1.9284946918487549, 'logits/chosen': -1.876366376876831, 'epoch': 0.13}\n",
      "{'loss': 0.0226, 'grad_norm': 1.9855660200119019, 'learning_rate': 0.0001546948158122427, 'rewards/chosen': -0.11867222189903259, 'rewards/rejected': -6.037182807922363, 'rewards/accuracies': 1.0, 'rewards/margins': 5.918510437011719, 'logps/rejected': -176.63018798828125, 'logps/chosen': -187.8868408203125, 'logits/rejected': -1.97298264503479, 'logits/chosen': -1.9086956977844238, 'epoch': 0.13}\n",
      "{'loss': 0.1994, 'grad_norm': 13.971480369567871, 'learning_rate': 0.0001533031728727994, 'rewards/chosen': -1.5662957429885864, 'rewards/rejected': -4.510420799255371, 'rewards/accuracies': 1.0, 'rewards/margins': 2.944125175476074, 'logps/rejected': -187.2264404296875, 'logps/chosen': -170.3253936767578, 'logits/rejected': -1.6151779890060425, 'logits/chosen': -1.8291953802108765, 'epoch': 0.14}\n",
      "{'loss': 0.0062, 'grad_norm': 0.49023810029029846, 'learning_rate': 0.00015189695737812152, 'rewards/chosen': 1.0880111455917358, 'rewards/rejected': -8.022188186645508, 'rewards/accuracies': 1.0, 'rewards/margins': 9.110199928283691, 'logps/rejected': -209.43382263183594, 'logps/chosen': -157.4412841796875, 'logits/rejected': -1.6856226921081543, 'logits/chosen': -1.9251508712768555, 'epoch': 0.14}\n",
      "{'loss': 0.2276, 'grad_norm': 16.43130111694336, 'learning_rate': 0.0001504765537734844, 'rewards/chosen': -1.3021717071533203, 'rewards/rejected': -6.342610836029053, 'rewards/accuracies': 0.75, 'rewards/margins': 5.040439128875732, 'logps/rejected': -169.39158630371094, 'logps/chosen': -180.2433624267578, 'logits/rejected': -1.9103258848190308, 'logits/chosen': -1.6477466821670532, 'epoch': 0.14}\n",
      "{'loss': 0.0416, 'grad_norm': 2.5297627449035645, 'learning_rate': 0.00014904235038305083, 'rewards/chosen': -2.4650449752807617, 'rewards/rejected': -6.998706817626953, 'rewards/accuracies': 1.0, 'rewards/margins': 4.533661842346191, 'logps/rejected': -184.76661682128906, 'logps/chosen': -167.37075805664062, 'logits/rejected': -1.8956838846206665, 'logits/chosen': -1.9364759922027588, 'epoch': 0.14}\n",
      "{'loss': 0.2109, 'grad_norm': 11.64871883392334, 'learning_rate': 0.00014759473930370736, 'rewards/chosen': -1.3323593139648438, 'rewards/rejected': -6.7899394035339355, 'rewards/accuracies': 1.0, 'rewards/margins': 5.457580089569092, 'logps/rejected': -172.65724182128906, 'logps/chosen': -219.6779022216797, 'logits/rejected': -1.7459330558776855, 'logits/chosen': -1.2956187725067139, 'epoch': 0.14}\n",
      "{'loss': 0.0036, 'grad_norm': 0.3608981966972351, 'learning_rate': 0.0001461341162978688, 'rewards/chosen': 0.16304096579551697, 'rewards/rejected': -7.80439567565918, 'rewards/accuracies': 1.0, 'rewards/margins': 7.967436790466309, 'logps/rejected': -186.13140869140625, 'logps/chosen': -202.26409912109375, 'logits/rejected': -2.036874294281006, 'logits/chosen': -1.7628173828125, 'epoch': 0.15}\n",
      "{'loss': 0.0025, 'grad_norm': 0.2144860327243805, 'learning_rate': 0.00014466088068528068, 'rewards/chosen': -1.9409570693969727, 'rewards/rejected': -8.378069877624512, 'rewards/accuracies': 1.0, 'rewards/margins': 6.437112808227539, 'logps/rejected': -207.99667358398438, 'logps/chosen': -142.56289672851562, 'logits/rejected': -1.7336195707321167, 'logits/chosen': -2.1005702018737793, 'epoch': 0.15}\n",
      "{'loss': 0.0073, 'grad_norm': 0.8001917600631714, 'learning_rate': 0.00014317543523384928, 'rewards/chosen': -1.1590049266815186, 'rewards/rejected': -9.266313552856445, 'rewards/accuracies': 1.0, 'rewards/margins': 8.107308387756348, 'logps/rejected': -222.93988037109375, 'logps/chosen': -183.2116241455078, 'logits/rejected': -1.907404899597168, 'logits/chosen': -2.147977828979492, 'epoch': 0.15}\n",
      "{'loss': 0.0006, 'grad_norm': 0.05796080827713013, 'learning_rate': 0.00014167818604952906, 'rewards/chosen': -1.195198893547058, 'rewards/rejected': -10.606522560119629, 'rewards/accuracies': 1.0, 'rewards/margins': 9.411323547363281, 'logps/rejected': -226.19424438476562, 'logps/chosen': -218.33682250976562, 'logits/rejected': -1.8555405139923096, 'logits/chosen': -1.8880020380020142, 'epoch': 0.15}\n",
      "{'loss': 0.1215, 'grad_norm': 7.021279335021973, 'learning_rate': 0.00014016954246529696, 'rewards/chosen': -3.855736494064331, 'rewards/rejected': -7.424864292144775, 'rewards/accuracies': 1.0, 'rewards/margins': 3.5691282749176025, 'logps/rejected': -187.12612915039062, 'logps/chosen': -202.37306213378906, 'logits/rejected': -2.0739448070526123, 'logits/chosen': -2.1591265201568604, 'epoch': 0.15}\n",
      "{'loss': 0.0034, 'grad_norm': 0.24138423800468445, 'learning_rate': 0.00013864991692924523, 'rewards/chosen': -3.7863247394561768, 'rewards/rejected': -10.44173526763916, 'rewards/accuracies': 1.0, 'rewards/margins': 6.655409812927246, 'logps/rejected': -196.6013946533203, 'logps/chosen': -190.14572143554688, 'logits/rejected': -1.9870253801345825, 'logits/chosen': -1.9794816970825195, 'epoch': 0.15}\n",
      "{'loss': 0.147, 'grad_norm': 8.25395679473877, 'learning_rate': 0.00013711972489182208, 'rewards/chosen': -4.399972915649414, 'rewards/rejected': -7.855990409851074, 'rewards/accuracies': 1.0, 'rewards/margins': 3.456017017364502, 'logps/rejected': -182.99000549316406, 'logps/chosen': -174.656005859375, 'logits/rejected': -2.032316207885742, 'logits/chosen': -2.104856491088867, 'epoch': 0.16}\n",
      "{'loss': 0.0145, 'grad_norm': 1.4042596817016602, 'learning_rate': 0.00013557938469225167, 'rewards/chosen': -2.268679618835449, 'rewards/rejected': -9.372106552124023, 'rewards/accuracies': 1.0, 'rewards/margins': 7.103426456451416, 'logps/rejected': -206.5559539794922, 'logps/chosen': -189.74197387695312, 'logits/rejected': -1.8325519561767578, 'logits/chosen': -1.8608652353286743, 'epoch': 0.16}\n",
      "{'loss': 0.1421, 'grad_norm': 3.999607563018799, 'learning_rate': 0.00013402931744416433, 'rewards/chosen': -3.835358142852783, 'rewards/rejected': -8.20110034942627, 'rewards/accuracies': 1.0, 'rewards/margins': 4.365741729736328, 'logps/rejected': -175.3539581298828, 'logps/chosen': -171.47544860839844, 'logits/rejected': -1.8808945417404175, 'logits/chosen': -1.873500108718872, 'epoch': 0.16}\n",
      "{'loss': 0.0044, 'grad_norm': 0.3953498899936676, 'learning_rate': 0.00013246994692046836, 'rewards/chosen': -3.0791563987731934, 'rewards/rejected': -10.722367286682129, 'rewards/accuracies': 1.0, 'rewards/margins': 7.643210411071777, 'logps/rejected': -260.52911376953125, 'logps/chosen': -208.936767578125, 'logits/rejected': -1.9678281545639038, 'logits/chosen': -2.0282552242279053, 'epoch': 0.16}\n",
      "{'loss': 0.0268, 'grad_norm': 1.2827253341674805, 'learning_rate': 0.00013090169943749476, 'rewards/chosen': -1.3565372228622437, 'rewards/rejected': -7.918115615844727, 'rewards/accuracies': 1.0, 'rewards/margins': 6.561578750610352, 'logps/rejected': -189.83099365234375, 'logps/chosen': -160.6901397705078, 'logits/rejected': -1.7876068353652954, 'logits/chosen': -1.7429324388504028, 'epoch': 0.16}\n",
      "{'loss': 0.0027, 'grad_norm': 0.2052648663520813, 'learning_rate': 0.0001293250037384465, 'rewards/chosen': -2.0389130115509033, 'rewards/rejected': -8.993643760681152, 'rewards/accuracies': 1.0, 'rewards/margins': 6.954730033874512, 'logps/rejected': -189.1672821044922, 'logps/chosen': -187.0417938232422, 'logits/rejected': -2.0021402835845947, 'logits/chosen': -2.0186407566070557, 'epoch': 0.17}\n",
      "{'loss': 0.1666, 'grad_norm': 9.118724822998047, 'learning_rate': 0.00012774029087618446, 'rewards/chosen': -3.1873276233673096, 'rewards/rejected': -6.084574222564697, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8972465991973877, 'logps/rejected': -143.94967651367188, 'logps/chosen': -149.68075561523438, 'logits/rejected': -2.082157850265503, 'logits/chosen': -2.0371923446655273, 'epoch': 0.17}\n",
      "{'loss': 0.0462, 'grad_norm': 2.236562967300415, 'learning_rate': 0.00012614799409538198, 'rewards/chosen': -3.177992820739746, 'rewards/rejected': -9.678346633911133, 'rewards/accuracies': 1.0, 'rewards/margins': 6.500354290008545, 'logps/rejected': -188.14434814453125, 'logps/chosen': -170.88804626464844, 'logits/rejected': -2.0042121410369873, 'logits/chosen': -2.0499277114868164, 'epoch': 0.17}\n",
      "{'loss': 0.0066, 'grad_norm': 0.5193730592727661, 'learning_rate': 0.00012454854871407994, 'rewards/chosen': -1.5853606462478638, 'rewards/rejected': -7.632745265960693, 'rewards/accuracies': 1.0, 'rewards/margins': 6.047383785247803, 'logps/rejected': -210.06356811523438, 'logps/chosen': -198.038330078125, 'logits/rejected': -1.8823237419128418, 'logits/chosen': -1.9488883018493652, 'epoch': 0.17}\n",
      "{'loss': 0.0129, 'grad_norm': 1.3283531665802002, 'learning_rate': 0.00012294239200467516, 'rewards/chosen': -1.3535858392715454, 'rewards/rejected': -8.614715576171875, 'rewards/accuracies': 1.0, 'rewards/margins': 7.261129379272461, 'logps/rejected': -198.05142211914062, 'logps/chosen': -190.31228637695312, 'logits/rejected': -1.7483108043670654, 'logits/chosen': -1.607642412185669, 'epoch': 0.17}\n",
      "{'loss': 0.177, 'grad_norm': 7.7134833335876465, 'learning_rate': 0.0001213299630743747, 'rewards/chosen': -2.9252004623413086, 'rewards/rejected': -10.478535652160645, 'rewards/accuracies': 0.75, 'rewards/margins': 7.553334712982178, 'logps/rejected': -213.47857666015625, 'logps/chosen': -180.04322814941406, 'logits/rejected': -2.0074641704559326, 'logits/chosen': -1.871736764907837, 'epoch': 0.17}\n",
      "{'loss': 0.0226, 'grad_norm': 1.9414911270141602, 'learning_rate': 0.00011971170274514802, 'rewards/chosen': -1.8450261354446411, 'rewards/rejected': -8.967950820922852, 'rewards/accuracies': 1.0, 'rewards/margins': 7.1229248046875, 'logps/rejected': -223.28842163085938, 'logps/chosen': -194.96226501464844, 'logits/rejected': -2.170898199081421, 'logits/chosen': -2.1732373237609863, 'epoch': 0.18}\n",
      "{'loss': 0.13, 'grad_norm': 9.952988624572754, 'learning_rate': 0.000118088053433211, 'rewards/chosen': 0.060514092445373535, 'rewards/rejected': -5.563713073730469, 'rewards/accuracies': 1.0, 'rewards/margins': 5.624227523803711, 'logps/rejected': -191.07205200195312, 'logps/chosen': -148.1488037109375, 'logits/rejected': -2.172647476196289, 'logits/chosen': -2.2813234329223633, 'epoch': 0.18}\n",
      "{'loss': 0.0102, 'grad_norm': 0.7475258111953735, 'learning_rate': 0.00011645945902807341, 'rewards/chosen': -2.209451675415039, 'rewards/rejected': -8.18507194519043, 'rewards/accuracies': 1.0, 'rewards/margins': 5.975619316101074, 'logps/rejected': -201.75381469726562, 'logps/chosen': -164.44515991210938, 'logits/rejected': -2.348104953765869, 'logits/chosen': -2.5346310138702393, 'epoch': 0.18}\n",
      "{'loss': 0.0367, 'grad_norm': 4.559559345245361, 'learning_rate': 0.0001148263647711842, 'rewards/chosen': -1.5350743532180786, 'rewards/rejected': -7.657497882843018, 'rewards/accuracies': 1.0, 'rewards/margins': 6.12242317199707, 'logps/rejected': -210.67666625976562, 'logps/chosen': -189.14959716796875, 'logits/rejected': -1.9897806644439697, 'logits/chosen': -2.131216526031494, 'epoch': 0.18}\n",
      "{'loss': 0.0231, 'grad_norm': 2.4042208194732666, 'learning_rate': 0.00011318921713420691, 'rewards/chosen': -2.916848659515381, 'rewards/rejected': -7.101376533508301, 'rewards/accuracies': 1.0, 'rewards/margins': 4.184528350830078, 'logps/rejected': -184.573974609375, 'logps/chosen': -205.296875, 'logits/rejected': -2.152787446975708, 'logits/chosen': -2.2370376586914062, 'epoch': 0.18}\n",
      "{'loss': 0.0186, 'grad_norm': 1.3498810529708862, 'learning_rate': 0.00011154846369695863, 'rewards/chosen': -1.748373031616211, 'rewards/rejected': -7.615652561187744, 'rewards/accuracies': 1.0, 'rewards/margins': 5.867280006408691, 'logps/rejected': -193.20718383789062, 'logps/chosen': -181.34555053710938, 'logits/rejected': -2.086235523223877, 'logits/chosen': -2.127819776535034, 'epoch': 0.19}\n",
      "{'loss': 0.0211, 'grad_norm': 1.914159893989563, 'learning_rate': 0.0001099045530250463, 'rewards/chosen': -5.010763645172119, 'rewards/rejected': -11.74547004699707, 'rewards/accuracies': 1.0, 'rewards/margins': 6.734706878662109, 'logps/rejected': -216.61724853515625, 'logps/chosen': -214.96160888671875, 'logits/rejected': -2.206913948059082, 'logits/chosen': -2.3231112957000732, 'epoch': 0.19}\n",
      "{'loss': 0.0023, 'grad_norm': 0.2591741979122162, 'learning_rate': 0.00010825793454723325, 'rewards/chosen': -3.0307555198669434, 'rewards/rejected': -12.495737075805664, 'rewards/accuracies': 1.0, 'rewards/margins': 9.464981079101562, 'logps/rejected': -232.03158569335938, 'logps/chosen': -185.38890075683594, 'logits/rejected': -2.209113836288452, 'logits/chosen': -2.2082102298736572, 'epoch': 0.19}\n",
      "{'loss': 0.1241, 'grad_norm': 6.096822261810303, 'learning_rate': 0.00010660905843256994, 'rewards/chosen': -4.138023853302002, 'rewards/rejected': -8.843513488769531, 'rewards/accuracies': 1.0, 'rewards/margins': 4.7054901123046875, 'logps/rejected': -188.49072265625, 'logps/chosen': -169.12258911132812, 'logits/rejected': -2.25445294380188, 'logits/chosen': -2.4032998085021973, 'epoch': 0.19}\n",
      "{'loss': 0.0095, 'grad_norm': 0.8500543832778931, 'learning_rate': 0.00010495837546732224, 'rewards/chosen': -4.761361598968506, 'rewards/rejected': -11.354687690734863, 'rewards/accuracies': 1.0, 'rewards/margins': 6.593326091766357, 'logps/rejected': -233.01220703125, 'logps/chosen': -207.24868774414062, 'logits/rejected': -2.2707090377807617, 'logits/chosen': -2.48520827293396, 'epoch': 0.19}\n",
      "{'loss': 0.0014, 'grad_norm': 0.14948411285877228, 'learning_rate': 0.00010330633693173082, 'rewards/chosen': -3.871555805206299, 'rewards/rejected': -11.156998634338379, 'rewards/accuracies': 1.0, 'rewards/margins': 7.285442352294922, 'logps/rejected': -219.26205444335938, 'logps/chosen': -192.3463592529297, 'logits/rejected': -2.3132011890411377, 'logits/chosen': -2.359299659729004, 'epoch': 0.19}\n",
      "{'loss': 0.0001, 'grad_norm': 0.01090582087635994, 'learning_rate': 0.00010165339447663587, 'rewards/chosen': -3.172739028930664, 'rewards/rejected': -13.954038619995117, 'rewards/accuracies': 1.0, 'rewards/margins': 10.781299591064453, 'logps/rejected': -260.3391418457031, 'logps/chosen': -193.8284912109375, 'logits/rejected': -2.1785151958465576, 'logits/chosen': -2.2871897220611572, 'epoch': 0.2}\n",
      "{'loss': 0.0575, 'grad_norm': 7.345174789428711, 'learning_rate': 0.0001, 'rewards/chosen': -5.048496246337891, 'rewards/rejected': -10.753580093383789, 'rewards/accuracies': 1.0, 'rewards/margins': 5.705082893371582, 'logps/rejected': -201.48341369628906, 'logps/chosen': -198.6976318359375, 'logits/rejected': -2.2160091400146484, 'logits/chosen': -2.1935863494873047, 'epoch': 0.2}\n",
      "{'loss': 0.0005, 'grad_norm': 0.08557668328285217, 'learning_rate': 9.834660552336415e-05, 'rewards/chosen': -5.062355041503906, 'rewards/rejected': -16.020116806030273, 'rewards/accuracies': 1.0, 'rewards/margins': 10.95776081085205, 'logps/rejected': -324.17510986328125, 'logps/chosen': -257.237548828125, 'logits/rejected': -2.1998400688171387, 'logits/chosen': -2.244020700454712, 'epoch': 0.2}\n",
      "{'loss': 0.0042, 'grad_norm': 0.24032479524612427, 'learning_rate': 9.669366306826919e-05, 'rewards/chosen': -4.935288429260254, 'rewards/rejected': -11.57081413269043, 'rewards/accuracies': 1.0, 'rewards/margins': 6.635525703430176, 'logps/rejected': -222.4033966064453, 'logps/chosen': -179.17906188964844, 'logits/rejected': -2.196850299835205, 'logits/chosen': -2.3976738452911377, 'epoch': 0.2}\n",
      "{'loss': 0.0001, 'grad_norm': 0.009124875999987125, 'learning_rate': 9.504162453267777e-05, 'rewards/chosen': -3.094439744949341, 'rewards/rejected': -13.340081214904785, 'rewards/accuracies': 1.0, 'rewards/margins': 10.245641708374023, 'logps/rejected': -238.13296508789062, 'logps/chosen': -220.348876953125, 'logits/rejected': -2.2370128631591797, 'logits/chosen': -2.3757574558258057, 'epoch': 0.2}\n",
      "{'loss': 0.0003, 'grad_norm': 0.051501937210559845, 'learning_rate': 9.339094156743007e-05, 'rewards/chosen': -0.45210766792297363, 'rewards/rejected': -10.216559410095215, 'rewards/accuracies': 1.0, 'rewards/margins': 9.764451026916504, 'logps/rejected': -205.38433837890625, 'logps/chosen': -204.26296997070312, 'logits/rejected': -2.2288968563079834, 'logits/chosen': -2.1364665031433105, 'epoch': 0.21}\n",
      "{'loss': 0.0, 'grad_norm': 0.0026484543923288584, 'learning_rate': 9.174206545276677e-05, 'rewards/chosen': -1.517114281654358, 'rewards/rejected': -11.848657608032227, 'rewards/accuracies': 1.0, 'rewards/margins': 10.331543922424316, 'logps/rejected': -249.73977661132812, 'logps/chosen': -208.65762329101562, 'logits/rejected': -2.1620450019836426, 'logits/chosen': -2.4336259365081787, 'epoch': 0.21}\n",
      "{'loss': 0.0, 'grad_norm': 0.00032267882488667965, 'learning_rate': 9.009544697495374e-05, 'rewards/chosen': -1.3499162197113037, 'rewards/rejected': -14.655263900756836, 'rewards/accuracies': 1.0, 'rewards/margins': 13.305347442626953, 'logps/rejected': -252.46115112304688, 'logps/chosen': -152.91139221191406, 'logits/rejected': -2.340942621231079, 'logits/chosen': -2.4238853454589844, 'epoch': 0.21}\n",
      "{'loss': 0.0013, 'grad_norm': 0.14883635938167572, 'learning_rate': 8.845153630304139e-05, 'rewards/chosen': -2.9695587158203125, 'rewards/rejected': -13.107606887817383, 'rewards/accuracies': 1.0, 'rewards/margins': 10.13804817199707, 'logps/rejected': -236.62905883789062, 'logps/chosen': -186.24864196777344, 'logits/rejected': -2.279391288757324, 'logits/chosen': -2.3682196140289307, 'epoch': 0.21}\n",
      "{'loss': 0.0438, 'grad_norm': 3.800398826599121, 'learning_rate': 8.681078286579311e-05, 'rewards/chosen': -6.739576816558838, 'rewards/rejected': -13.387748718261719, 'rewards/accuracies': 1.0, 'rewards/margins': 6.648171424865723, 'logps/rejected': -240.56759643554688, 'logps/chosen': -182.281982421875, 'logits/rejected': -2.5163049697875977, 'logits/chosen': -2.5381057262420654, 'epoch': 0.21}\n",
      "{'loss': 0.0001, 'grad_norm': 0.007124728057533503, 'learning_rate': 8.517363522881579e-05, 'rewards/chosen': -1.336308240890503, 'rewards/rejected': -12.253009796142578, 'rewards/accuracies': 1.0, 'rewards/margins': 10.91670036315918, 'logps/rejected': -250.26040649414062, 'logps/chosen': -195.16287231445312, 'logits/rejected': -2.1400656700134277, 'logits/chosen': -2.4695653915405273, 'epoch': 0.21}\n",
      "{'loss': 0.0, 'grad_norm': 0.0014090633485466242, 'learning_rate': 8.35405409719266e-05, 'rewards/chosen': -1.523581862449646, 'rewards/rejected': -13.349681854248047, 'rewards/accuracies': 1.0, 'rewards/margins': 11.826099395751953, 'logps/rejected': -244.8816680908203, 'logps/chosen': -174.87744140625, 'logits/rejected': -2.0674195289611816, 'logits/chosen': -2.2117042541503906, 'epoch': 0.22}\n",
      "{'loss': 0.0007, 'grad_norm': 0.05987649783492088, 'learning_rate': 8.191194656678904e-05, 'rewards/chosen': -3.821601390838623, 'rewards/rejected': -13.123188972473145, 'rewards/accuracies': 1.0, 'rewards/margins': 9.30158805847168, 'logps/rejected': -238.67324829101562, 'logps/chosen': -202.77694702148438, 'logits/rejected': -2.1462554931640625, 'logits/chosen': -2.3043203353881836, 'epoch': 0.22}\n",
      "{'loss': 0.0001, 'grad_norm': 0.010963601991534233, 'learning_rate': 8.028829725485199e-05, 'rewards/chosen': -2.5276756286621094, 'rewards/rejected': -14.410829544067383, 'rewards/accuracies': 1.0, 'rewards/margins': 11.88315486907959, 'logps/rejected': -249.29318237304688, 'logps/chosen': -185.9898681640625, 'logits/rejected': -2.1372690200805664, 'logits/chosen': -2.304741621017456, 'epoch': 0.22}\n",
      "{'loss': 0.0019, 'grad_norm': 0.36031898856163025, 'learning_rate': 7.867003692562534e-05, 'rewards/chosen': -3.8206889629364014, 'rewards/rejected': -14.04332447052002, 'rewards/accuracies': 1.0, 'rewards/margins': 10.222637176513672, 'logps/rejected': -253.017578125, 'logps/chosen': -193.40536499023438, 'logits/rejected': -2.2065510749816895, 'logits/chosen': -2.3927650451660156, 'epoch': 0.22}\n",
      "{'loss': 0.0112, 'grad_norm': 1.1176669597625732, 'learning_rate': 7.705760799532485e-05, 'rewards/chosen': -4.0896782875061035, 'rewards/rejected': -11.618269920349121, 'rewards/accuracies': 1.0, 'rewards/margins': 7.528591632843018, 'logps/rejected': -229.54669189453125, 'logps/chosen': -163.12203979492188, 'logits/rejected': -2.221769094467163, 'logits/chosen': -2.419822931289673, 'epoch': 0.22}\n",
      "{'loss': 0.1677, 'grad_norm': 6.860163688659668, 'learning_rate': 7.54514512859201e-05, 'rewards/chosen': -4.078863620758057, 'rewards/rejected': -10.592464447021484, 'rewards/accuracies': 1.0, 'rewards/margins': 6.513599872589111, 'logps/rejected': -200.8982391357422, 'logps/chosen': -164.24046325683594, 'logits/rejected': -2.242830276489258, 'logits/chosen': -2.260417938232422, 'epoch': 0.23}\n",
      "{'loss': 0.0325, 'grad_norm': 3.585195541381836, 'learning_rate': 7.385200590461803e-05, 'rewards/chosen': -1.3471440076828003, 'rewards/rejected': -12.168654441833496, 'rewards/accuracies': 1.0, 'rewards/margins': 10.821510314941406, 'logps/rejected': -244.46173095703125, 'logps/chosen': -213.35549926757812, 'logits/rejected': -2.165069818496704, 'logits/chosen': -1.9671604633331299, 'epoch': 0.23}\n",
      "{'loss': 0.0001, 'grad_norm': 0.006816816050559282, 'learning_rate': 7.225970912381556e-05, 'rewards/chosen': -2.3450894355773926, 'rewards/rejected': -13.796333312988281, 'rewards/accuracies': 1.0, 'rewards/margins': 11.451244354248047, 'logps/rejected': -282.52801513671875, 'logps/chosen': -238.04339599609375, 'logits/rejected': -2.2153079509735107, 'logits/chosen': -2.3363304138183594, 'epoch': 0.23}\n",
      "{'loss': 0.001, 'grad_norm': 0.10302639752626419, 'learning_rate': 7.067499626155354e-05, 'rewards/chosen': -2.0455474853515625, 'rewards/rejected': -12.272953033447266, 'rewards/accuracies': 1.0, 'rewards/margins': 10.227405548095703, 'logps/rejected': -256.5802307128906, 'logps/chosen': -219.22613525390625, 'logits/rejected': -2.1114869117736816, 'logits/chosen': -2.219487190246582, 'epoch': 0.23}\n",
      "{'loss': 0.0258, 'grad_norm': 3.7436485290527344, 'learning_rate': 6.909830056250527e-05, 'rewards/chosen': -5.343659400939941, 'rewards/rejected': -11.206758499145508, 'rewards/accuracies': 1.0, 'rewards/margins': 5.863099098205566, 'logps/rejected': -209.470947265625, 'logps/chosen': -196.35379028320312, 'logits/rejected': -2.1186399459838867, 'logits/chosen': -2.258011817932129, 'epoch': 0.23}\n",
      "{'loss': 0.0005, 'grad_norm': 0.04774291068315506, 'learning_rate': 6.753005307953167e-05, 'rewards/chosen': -1.056403398513794, 'rewards/rejected': -11.622352600097656, 'rewards/accuracies': 1.0, 'rewards/margins': 10.565948486328125, 'logps/rejected': -230.46087646484375, 'logps/chosen': -203.02639770507812, 'logits/rejected': -2.2768588066101074, 'logits/chosen': -2.3190207481384277, 'epoch': 0.23}\n",
      "{'loss': 0.1228, 'grad_norm': 5.038941383361816, 'learning_rate': 6.59706825558357e-05, 'rewards/chosen': -4.477744102478027, 'rewards/rejected': -14.920291900634766, 'rewards/accuracies': 1.0, 'rewards/margins': 10.442547798156738, 'logps/rejected': -254.47149658203125, 'logps/chosen': -175.0951690673828, 'logits/rejected': -2.192202091217041, 'logits/chosen': -2.2543582916259766, 'epoch': 0.24}\n",
      "{'loss': 0.001, 'grad_norm': 0.09343224763870239, 'learning_rate': 6.442061530774834e-05, 'rewards/chosen': -1.1879321336746216, 'rewards/rejected': -9.510787963867188, 'rewards/accuracies': 1.0, 'rewards/margins': 8.322854995727539, 'logps/rejected': -201.59414672851562, 'logps/chosen': -178.17906188964844, 'logits/rejected': -2.129725694656372, 'logits/chosen': -2.162785291671753, 'epoch': 0.24}\n",
      "{'loss': 0.0101, 'grad_norm': 1.2167553901672363, 'learning_rate': 6.28802751081779e-05, 'rewards/chosen': -2.217557430267334, 'rewards/rejected': -8.696144104003906, 'rewards/accuracies': 1.0, 'rewards/margins': 6.478586196899414, 'logps/rejected': -208.76638793945312, 'logps/chosen': -199.0727081298828, 'logits/rejected': -2.121725559234619, 'logits/chosen': -2.224928379058838, 'epoch': 0.24}\n",
      "{'loss': 0.0093, 'grad_norm': 1.390912652015686, 'learning_rate': 6.135008307075481e-05, 'rewards/chosen': -2.711087465286255, 'rewards/rejected': -13.99371337890625, 'rewards/accuracies': 1.0, 'rewards/margins': 11.282626152038574, 'logps/rejected': -251.92398071289062, 'logps/chosen': -192.79515075683594, 'logits/rejected': -2.2711522579193115, 'logits/chosen': -2.4924864768981934, 'epoch': 0.24}\n",
      "{'loss': 0.1258, 'grad_norm': 16.631484985351562, 'learning_rate': 5.983045753470308e-05, 'rewards/chosen': -3.5530757904052734, 'rewards/rejected': -8.254802703857422, 'rewards/accuracies': 1.0, 'rewards/margins': 4.701726913452148, 'logps/rejected': -175.0729522705078, 'logps/chosen': -175.2684326171875, 'logits/rejected': -2.0888543128967285, 'logits/chosen': -2.020740032196045, 'epoch': 0.24}\n",
      "{'loss': 0.0115, 'grad_norm': 1.146403431892395, 'learning_rate': 5.832181395047098e-05, 'rewards/chosen': -3.2815780639648438, 'rewards/rejected': -9.477789878845215, 'rewards/accuracies': 1.0, 'rewards/margins': 6.196211814880371, 'logps/rejected': -207.09689331054688, 'logps/chosen': -155.68112182617188, 'logits/rejected': -2.445319175720215, 'logits/chosen': -2.3686094284057617, 'epoch': 0.25}\n",
      "{'loss': 0.0314, 'grad_norm': 2.031463623046875, 'learning_rate': 5.6824564766150726e-05, 'rewards/chosen': -3.6152329444885254, 'rewards/rejected': -12.78016185760498, 'rewards/accuracies': 1.0, 'rewards/margins': 9.164928436279297, 'logps/rejected': -230.65174865722656, 'logps/chosen': -182.6053009033203, 'logits/rejected': -2.2075252532958984, 'logits/chosen': -2.0880126953125, 'epoch': 0.25}\n",
      "{'loss': 0.0672, 'grad_norm': 4.178508758544922, 'learning_rate': 5.533911931471936e-05, 'rewards/chosen': -2.5602478981018066, 'rewards/rejected': -10.318222045898438, 'rewards/accuracies': 1.0, 'rewards/margins': 7.757974147796631, 'logps/rejected': -195.44921875, 'logps/chosen': -132.1256561279297, 'logits/rejected': -2.269003391265869, 'logits/chosen': -2.276331901550293, 'epoch': 0.25}\n",
      "{'loss': 0.0022, 'grad_norm': 0.13851411640644073, 'learning_rate': 5.386588370213124e-05, 'rewards/chosen': -2.9372518062591553, 'rewards/rejected': -10.02334976196289, 'rewards/accuracies': 1.0, 'rewards/margins': 7.086098670959473, 'logps/rejected': -204.04022216796875, 'logps/chosen': -168.47283935546875, 'logits/rejected': -2.186284303665161, 'logits/chosen': -2.2344491481781006, 'epoch': 0.25}\n",
      "{'loss': 0.0042, 'grad_norm': 0.4399718940258026, 'learning_rate': 5.240526069629265e-05, 'rewards/chosen': -2.1997807025909424, 'rewards/rejected': -9.630326271057129, 'rewards/accuracies': 1.0, 'rewards/margins': 7.430546760559082, 'logps/rejected': -219.71914672851562, 'logps/chosen': -216.9431610107422, 'logits/rejected': -2.2096853256225586, 'logits/chosen': -2.212486982345581, 'epoch': 0.25}\n",
      "{'loss': 0.0001, 'grad_norm': 0.011903546750545502, 'learning_rate': 5.095764961694922e-05, 'rewards/chosen': -0.21130946278572083, 'rewards/rejected': -11.046830177307129, 'rewards/accuracies': 1.0, 'rewards/margins': 10.835521697998047, 'logps/rejected': -227.42083740234375, 'logps/chosen': -190.74560546875, 'logits/rejected': -2.1890313625335693, 'logits/chosen': -2.2413430213928223, 'epoch': 0.26}\n",
      "{'loss': 0.0005, 'grad_norm': 0.05279070883989334, 'learning_rate': 4.952344622651566e-05, 'rewards/chosen': -2.6585586071014404, 'rewards/rejected': -11.747291564941406, 'rewards/accuracies': 1.0, 'rewards/margins': 9.08873176574707, 'logps/rejected': -227.77285766601562, 'logps/chosen': -190.08615112304688, 'logits/rejected': -2.2435383796691895, 'logits/chosen': -2.234513521194458, 'epoch': 0.26}\n",
      "{'loss': 0.0015, 'grad_norm': 0.18084126710891724, 'learning_rate': 4.810304262187852e-05, 'rewards/chosen': -1.6785591840744019, 'rewards/rejected': -11.079983711242676, 'rewards/accuracies': 1.0, 'rewards/margins': 9.401424407958984, 'logps/rejected': -251.57546997070312, 'logps/chosen': -196.89251708984375, 'logits/rejected': -2.2058231830596924, 'logits/chosen': -2.3668906688690186, 'epoch': 0.26}\n",
      "{'loss': 0.0288, 'grad_norm': 2.433781623840332, 'learning_rate': 4.669682712720065e-05, 'rewards/chosen': -3.421877384185791, 'rewards/rejected': -10.08975887298584, 'rewards/accuracies': 1.0, 'rewards/margins': 6.667881488800049, 'logps/rejected': -216.96096801757812, 'logps/chosen': -183.97189331054688, 'logits/rejected': -2.2854249477386475, 'logits/chosen': -2.372973680496216, 'epoch': 0.26}\n",
      "{'loss': 0.0096, 'grad_norm': 1.4238842725753784, 'learning_rate': 4.530518418775733e-05, 'rewards/chosen': -3.4995739459991455, 'rewards/rejected': -12.350914001464844, 'rewards/accuracies': 1.0, 'rewards/margins': 8.851339340209961, 'logps/rejected': -250.13546752929688, 'logps/chosen': -194.6492156982422, 'logits/rejected': -2.135260820388794, 'logits/chosen': -2.0642056465148926, 'epoch': 0.26}\n",
      "{'loss': 0.2385, 'grad_norm': 13.35928726196289, 'learning_rate': 4.392849426483274e-05, 'rewards/chosen': -6.006684303283691, 'rewards/rejected': -12.070521354675293, 'rewards/accuracies': 0.75, 'rewards/margins': 6.063837051391602, 'logps/rejected': -216.22666931152344, 'logps/chosen': -198.4078826904297, 'logits/rejected': -2.3584961891174316, 'logits/chosen': -2.5138349533081055, 'epoch': 0.26}\n",
      "{'loss': 0.0, 'grad_norm': 0.0010322548914700747, 'learning_rate': 4.256713373170564e-05, 'rewards/chosen': -3.484895706176758, 'rewards/rejected': -16.999752044677734, 'rewards/accuracies': 1.0, 'rewards/margins': 13.51485538482666, 'logps/rejected': -308.7020568847656, 'logps/chosen': -228.85516357421875, 'logits/rejected': -2.2783424854278564, 'logits/chosen': -2.352313280105591, 'epoch': 0.27}\n",
      "{'loss': 0.0622, 'grad_norm': 7.096729278564453, 'learning_rate': 4.12214747707527e-05, 'rewards/chosen': -4.411710262298584, 'rewards/rejected': -13.553522109985352, 'rewards/accuracies': 1.0, 'rewards/margins': 9.14181137084961, 'logps/rejected': -218.3641357421875, 'logps/chosen': -162.97869873046875, 'logits/rejected': -2.32871150970459, 'logits/chosen': -2.326596975326538, 'epoch': 0.27}\n",
      "{'loss': 0.1448, 'grad_norm': 6.523146152496338, 'learning_rate': 3.9891885271697496e-05, 'rewards/chosen': -4.104140281677246, 'rewards/rejected': -7.322607517242432, 'rewards/accuracies': 1.0, 'rewards/margins': 3.2184672355651855, 'logps/rejected': -194.8663787841797, 'logps/chosen': -189.5460662841797, 'logits/rejected': -2.263331413269043, 'logits/chosen': -2.3944759368896484, 'epoch': 0.27}\n",
      "{'loss': 0.1616, 'grad_norm': 2.549431800842285, 'learning_rate': 3.857872873103322e-05, 'rewards/chosen': -3.197097063064575, 'rewards/rejected': -8.577482223510742, 'rewards/accuracies': 1.0, 'rewards/margins': 5.38038444519043, 'logps/rejected': -204.89822387695312, 'logps/chosen': -159.82958984375, 'logits/rejected': -2.291311740875244, 'logits/chosen': -2.4618000984191895, 'epoch': 0.27}\n",
      "{'loss': 0.0024, 'grad_norm': 0.271746963262558, 'learning_rate': 3.7282364152646297e-05, 'rewards/chosen': -3.070821762084961, 'rewards/rejected': -12.19809627532959, 'rewards/accuracies': 1.0, 'rewards/margins': 9.127273559570312, 'logps/rejected': -231.45916748046875, 'logps/chosen': -182.3715362548828, 'logits/rejected': -2.2808947563171387, 'logits/chosen': -2.2702174186706543, 'epoch': 0.27}\n",
      "{'loss': 0.021, 'grad_norm': 3.0873451232910156, 'learning_rate': 3.600314594966834e-05, 'rewards/chosen': -5.808053970336914, 'rewards/rejected': -11.154200553894043, 'rewards/accuracies': 1.0, 'rewards/margins': 5.346146583557129, 'logps/rejected': -198.75692749023438, 'logps/chosen': -179.4291534423828, 'logits/rejected': -2.166820526123047, 'logits/chosen': -2.2252540588378906, 'epoch': 0.28}\n",
      "{'loss': 0.0081, 'grad_norm': 1.8337525129318237, 'learning_rate': 3.4741423847583134e-05, 'rewards/chosen': -6.130826473236084, 'rewards/rejected': -17.962142944335938, 'rewards/accuracies': 1.0, 'rewards/margins': 11.831316947937012, 'logps/rejected': -291.9962158203125, 'logps/chosen': -206.93460083007812, 'logits/rejected': -2.4261653423309326, 'logits/chosen': -2.5769541263580322, 'epoch': 0.28}\n",
      "{'loss': 0.0323, 'grad_norm': 6.401522636413574, 'learning_rate': 3.349754278861517e-05, 'rewards/chosen': -8.079682350158691, 'rewards/rejected': -19.038780212402344, 'rewards/accuracies': 1.0, 'rewards/margins': 10.959096908569336, 'logps/rejected': -318.85107421875, 'logps/chosen': -235.4498291015625, 'logits/rejected': -2.39499831199646, 'logits/chosen': -2.4524824619293213, 'epoch': 0.28}\n",
      "{'loss': 0.0024, 'grad_norm': 0.24150420725345612, 'learning_rate': 3.227184283742591e-05, 'rewards/chosen': -4.173587799072266, 'rewards/rejected': -13.96065902709961, 'rewards/accuracies': 1.0, 'rewards/margins': 9.787070274353027, 'logps/rejected': -268.7438049316406, 'logps/chosen': -204.23684692382812, 'logits/rejected': -2.2802367210388184, 'logits/chosen': -2.4894866943359375, 'epoch': 0.28}\n",
      "{'loss': 0.3593, 'grad_norm': 8.118741035461426, 'learning_rate': 3.106465908814343e-05, 'rewards/chosen': -5.746129035949707, 'rewards/rejected': -12.157099723815918, 'rewards/accuracies': 0.75, 'rewards/margins': 6.410970687866211, 'logps/rejected': -216.4243621826172, 'logps/chosen': -199.4594268798828, 'logits/rejected': -2.2007033824920654, 'logits/chosen': -2.249972343444824, 'epoch': 0.28}\n",
      "{'loss': 0.0001, 'grad_norm': 0.006744235288351774, 'learning_rate': 2.9876321572751144e-05, 'rewards/chosen': -3.4894537925720215, 'rewards/rejected': -17.59016990661621, 'rewards/accuracies': 1.0, 'rewards/margins': 14.100716590881348, 'logps/rejected': -291.8970947265625, 'logps/chosen': -228.06390380859375, 'logits/rejected': -2.2147347927093506, 'logits/chosen': -2.2711188793182373, 'epoch': 0.28}\n",
      "{'loss': 0.0, 'grad_norm': 0.00627910764887929, 'learning_rate': 2.87071551708603e-05, 'rewards/chosen': -2.7639646530151367, 'rewards/rejected': -15.180604934692383, 'rewards/accuracies': 1.0, 'rewards/margins': 12.416640281677246, 'logps/rejected': -278.62213134765625, 'logps/chosen': -173.52975463867188, 'logits/rejected': -2.211944341659546, 'logits/chosen': -2.4640872478485107, 'epoch': 0.29}\n",
      "{'loss': 0.0099, 'grad_norm': 1.2371201515197754, 'learning_rate': 2.7557479520891104e-05, 'rewards/chosen': -2.203885555267334, 'rewards/rejected': -12.457169532775879, 'rewards/accuracies': 1.0, 'rewards/margins': 10.253284454345703, 'logps/rejected': -268.99688720703125, 'logps/chosen': -204.47018432617188, 'logits/rejected': -2.254969358444214, 'logits/chosen': -2.3254754543304443, 'epoch': 0.29}\n",
      "{'loss': 0.0031, 'grad_norm': 0.43255719542503357, 'learning_rate': 2.6427608932686843e-05, 'rewards/chosen': -4.003126621246338, 'rewards/rejected': -13.342630386352539, 'rewards/accuracies': 1.0, 'rewards/margins': 9.33950424194336, 'logps/rejected': -231.88397216796875, 'logps/chosen': -183.52813720703125, 'logits/rejected': -2.407700300216675, 'logits/chosen': -2.4993162155151367, 'epoch': 0.29}\n",
      "{'loss': 0.0316, 'grad_norm': 4.708630084991455, 'learning_rate': 2.5317852301584643e-05, 'rewards/chosen': -3.0033838748931885, 'rewards/rejected': -10.417067527770996, 'rewards/accuracies': 1.0, 'rewards/margins': 7.413683891296387, 'logps/rejected': -211.4735107421875, 'logps/chosen': -192.01638793945312, 'logits/rejected': -2.2437052726745605, 'logits/chosen': -2.3298003673553467, 'epoch': 0.29}\n",
      "{'loss': 0.0253, 'grad_norm': 2.9125330448150635, 'learning_rate': 2.422851302396656e-05, 'rewards/chosen': -2.035918951034546, 'rewards/rejected': -10.871105194091797, 'rewards/accuracies': 1.0, 'rewards/margins': 8.835186004638672, 'logps/rejected': -283.93572998046875, 'logps/chosen': -247.39285278320312, 'logits/rejected': -2.0958261489868164, 'logits/chosen': -2.145691156387329, 'epoch': 0.29}\n",
      "{'loss': 0.0077, 'grad_norm': 1.4945728778839111, 'learning_rate': 2.315988891431412e-05, 'rewards/chosen': -3.6935131549835205, 'rewards/rejected': -12.890650749206543, 'rewards/accuracies': 1.0, 'rewards/margins': 9.197136878967285, 'logps/rejected': -243.18594360351562, 'logps/chosen': -188.65672302246094, 'logits/rejected': -2.331590175628662, 'logits/chosen': -2.412503242492676, 'epoch': 0.3}\n",
      "{'loss': 0.0051, 'grad_norm': 0.7209554314613342, 'learning_rate': 2.2112272123788768e-05, 'rewards/chosen': -3.089482307434082, 'rewards/rejected': -13.373733520507812, 'rewards/accuracies': 1.0, 'rewards/margins': 10.284250259399414, 'logps/rejected': -271.7147521972656, 'logps/chosen': -194.336181640625, 'logits/rejected': -2.3578929901123047, 'logits/chosen': -2.4021873474121094, 'epoch': 0.3}\n",
      "{'loss': 0.0093, 'grad_norm': 1.3786406517028809, 'learning_rate': 2.1085949060360654e-05, 'rewards/chosen': -5.077098369598389, 'rewards/rejected': -13.964224815368652, 'rewards/accuracies': 1.0, 'rewards/margins': 8.887125968933105, 'logps/rejected': -259.61273193359375, 'logps/chosen': -257.08935546875, 'logits/rejected': -2.320017099380493, 'logits/chosen': -2.354368209838867, 'epoch': 0.3}\n",
      "{'loss': 0.0002, 'grad_norm': 0.04646114259958267, 'learning_rate': 2.008120031050753e-05, 'rewards/chosen': -1.9633946418762207, 'rewards/rejected': -14.091453552246094, 'rewards/accuracies': 1.0, 'rewards/margins': 12.128060340881348, 'logps/rejected': -247.7108917236328, 'logps/chosen': -157.43954467773438, 'logits/rejected': -2.3331589698791504, 'logits/chosen': -2.5387821197509766, 'epoch': 0.3}\n",
      "{'loss': 0.1091, 'grad_norm': 11.212995529174805, 'learning_rate': 1.9098300562505266e-05, 'rewards/chosen': -5.406778335571289, 'rewards/rejected': -15.282569885253906, 'rewards/accuracies': 1.0, 'rewards/margins': 9.875791549682617, 'logps/rejected': -241.6754150390625, 'logps/chosen': -171.5183563232422, 'logits/rejected': -2.418752670288086, 'logits/chosen': -2.460369825363159, 'epoch': 0.3}\n",
      "{'loss': 0.0002, 'grad_norm': 0.025500111281871796, 'learning_rate': 1.8137518531330767e-05, 'rewards/chosen': -1.9237399101257324, 'rewards/rejected': -12.06977653503418, 'rewards/accuracies': 1.0, 'rewards/margins': 10.146036148071289, 'logps/rejected': -277.17822265625, 'logps/chosen': -220.61935424804688, 'logits/rejected': -2.2244012355804443, 'logits/chosen': -2.3215854167938232, 'epoch': 0.3}\n",
      "{'loss': 0.0022, 'grad_norm': 0.4522553086280823, 'learning_rate': 1.7199116885197995e-05, 'rewards/chosen': -6.411786079406738, 'rewards/rejected': -14.907316207885742, 'rewards/accuracies': 1.0, 'rewards/margins': 8.49553108215332, 'logps/rejected': -247.3294219970703, 'logps/chosen': -188.03414916992188, 'logits/rejected': -2.3577663898468018, 'logits/chosen': -2.447968006134033, 'epoch': 0.31}\n",
      "{'loss': 0.0011, 'grad_norm': 0.1766446977853775, 'learning_rate': 1.6283352173747145e-05, 'rewards/chosen': -1.38273286819458, 'rewards/rejected': -10.885557174682617, 'rewards/accuracies': 1.0, 'rewards/margins': 9.502824783325195, 'logps/rejected': -216.22140502929688, 'logps/chosen': -165.8935546875, 'logits/rejected': -2.2436683177948, 'logits/chosen': -2.1671836376190186, 'epoch': 0.31}\n",
      "{'loss': 0.0566, 'grad_norm': 6.8429365158081055, 'learning_rate': 1.5390474757906446e-05, 'rewards/chosen': -2.718195915222168, 'rewards/rejected': -8.58428955078125, 'rewards/accuracies': 1.0, 'rewards/margins': 5.866093635559082, 'logps/rejected': -187.99984741210938, 'logps/chosen': -196.1515350341797, 'logits/rejected': -2.3155314922332764, 'logits/chosen': -2.098033905029297, 'epoch': 0.31}\n",
      "{'loss': 0.0585, 'grad_norm': 4.822711944580078, 'learning_rate': 1.4520728741446089e-05, 'rewards/chosen': -3.1036202907562256, 'rewards/rejected': -9.102985382080078, 'rewards/accuracies': 1.0, 'rewards/margins': 5.99936580657959, 'logps/rejected': -180.21286010742188, 'logps/chosen': -148.27093505859375, 'logits/rejected': -2.3796114921569824, 'logits/chosen': -2.378048896789551, 'epoch': 0.31}\n",
      "{'loss': 0.1155, 'grad_norm': 4.4225029945373535, 'learning_rate': 1.3674351904242611e-05, 'rewards/chosen': -5.070490837097168, 'rewards/rejected': -11.734285354614258, 'rewards/accuracies': 1.0, 'rewards/margins': 6.663795471191406, 'logps/rejected': -213.7344207763672, 'logps/chosen': -158.8555908203125, 'logits/rejected': -2.33819580078125, 'logits/chosen': -2.3320059776306152, 'epoch': 0.31}\n",
      "{'loss': 0.0409, 'grad_norm': 2.14262056350708, 'learning_rate': 1.2851575637272262e-05, 'rewards/chosen': -2.4838972091674805, 'rewards/rejected': -11.229766845703125, 'rewards/accuracies': 1.0, 'rewards/margins': 8.745868682861328, 'logps/rejected': -238.7822265625, 'logps/chosen': -181.21951293945312, 'logits/rejected': -2.339427947998047, 'logits/chosen': -2.3967528343200684, 'epoch': 0.32}\n",
      "{'loss': 0.0, 'grad_norm': 0.007963565178215504, 'learning_rate': 1.2052624879351104e-05, 'rewards/chosen': -2.7617321014404297, 'rewards/rejected': -14.746108055114746, 'rewards/accuracies': 1.0, 'rewards/margins': 11.984375, 'logps/rejected': -258.24493408203125, 'logps/chosen': -215.7035675048828, 'logits/rejected': -2.1745920181274414, 'logits/chosen': -2.2509636878967285, 'epoch': 0.32}\n",
      "{'loss': 1.0128, 'grad_norm': 32.90799331665039, 'learning_rate': 1.1277718055638819e-05, 'rewards/chosen': -4.062321662902832, 'rewards/rejected': -12.41104793548584, 'rewards/accuracies': 0.75, 'rewards/margins': 8.348726272583008, 'logps/rejected': -240.61883544921875, 'logps/chosen': -198.0765380859375, 'logits/rejected': -2.2532424926757812, 'logits/chosen': -1.9959561824798584, 'epoch': 0.32}\n",
      "{'loss': 0.0097, 'grad_norm': 1.492074966430664, 'learning_rate': 1.0527067017923654e-05, 'rewards/chosen': -3.1085314750671387, 'rewards/rejected': -12.80957317352295, 'rewards/accuracies': 1.0, 'rewards/margins': 9.701041221618652, 'logps/rejected': -245.7735595703125, 'logps/chosen': -190.4817352294922, 'logits/rejected': -2.2338244915008545, 'logits/chosen': -2.436058759689331, 'epoch': 0.32}\n",
      "{'loss': 0.0441, 'grad_norm': 6.939557075500488, 'learning_rate': 9.80087698670411e-06, 'rewards/chosen': -2.9146718978881836, 'rewards/rejected': -10.451205253601074, 'rewards/accuracies': 1.0, 'rewards/margins': 7.536532878875732, 'logps/rejected': -208.99359130859375, 'logps/chosen': -199.49127197265625, 'logits/rejected': -2.1514971256256104, 'logits/chosen': -2.269489049911499, 'epoch': 0.32}\n",
      "{'loss': 0.0071, 'grad_norm': 0.7609667778015137, 'learning_rate': 9.09934649508375e-06, 'rewards/chosen': -5.860882759094238, 'rewards/rejected': -12.682798385620117, 'rewards/accuracies': 1.0, 'rewards/margins': 6.8219146728515625, 'logps/rejected': -243.92202758789062, 'logps/chosen': -217.17379760742188, 'logits/rejected': -2.317020893096924, 'logits/chosen': -2.2978196144104004, 'epoch': 0.32}\n",
      "{'loss': 0.0016, 'grad_norm': 0.20206327736377716, 'learning_rate': 8.422667334494249e-06, 'rewards/chosen': -2.508002281188965, 'rewards/rejected': -11.511474609375, 'rewards/accuracies': 1.0, 'rewards/margins': 9.003471374511719, 'logps/rejected': -222.84722900390625, 'logps/chosen': -205.78794860839844, 'logits/rejected': -2.1774027347564697, 'logits/chosen': -2.321108341217041, 'epoch': 0.33}\n",
      "{'loss': 0.0067, 'grad_norm': 1.0323989391326904, 'learning_rate': 7.771024502261526e-06, 'rewards/chosen': -2.227724552154541, 'rewards/rejected': -11.531954765319824, 'rewards/accuracies': 1.0, 'rewards/margins': 9.304230690002441, 'logps/rejected': -221.4570770263672, 'logps/chosen': -168.80780029296875, 'logits/rejected': -2.333167314529419, 'logits/chosen': -2.556494951248169, 'epoch': 0.33}\n",
      "{'loss': 0.0278, 'grad_norm': 2.9208526611328125, 'learning_rate': 7.144596151029303e-06, 'rewards/chosen': -0.8153789639472961, 'rewards/rejected': -12.137521743774414, 'rewards/accuracies': 1.0, 'rewards/margins': 11.322141647338867, 'logps/rejected': -242.46688842773438, 'logps/chosen': -191.14305114746094, 'logits/rejected': -2.1933741569519043, 'logits/chosen': -2.2559444904327393, 'epoch': 0.33}\n",
      "{'loss': 0.0002, 'grad_norm': 0.03165842220187187, 'learning_rate': 6.543553540053926e-06, 'rewards/chosen': -4.401558876037598, 'rewards/rejected': -14.79507064819336, 'rewards/accuracies': 1.0, 'rewards/margins': 10.393509864807129, 'logps/rejected': -255.02655029296875, 'logps/chosen': -212.28724670410156, 'logits/rejected': -2.3152410984039307, 'logits/chosen': -2.3820433616638184, 'epoch': 0.33}\n",
      "{'loss': 0.0017, 'grad_norm': 0.28650981187820435, 'learning_rate': 5.968060988383883e-06, 'rewards/chosen': -4.300158500671387, 'rewards/rejected': -12.493940353393555, 'rewards/accuracies': 1.0, 'rewards/margins': 8.193781852722168, 'logps/rejected': -233.71078491210938, 'logps/chosen': -184.32748413085938, 'logits/rejected': -2.1851279735565186, 'logits/chosen': -2.358363389968872, 'epoch': 0.33}\n",
      "{'loss': 0.3107, 'grad_norm': 37.32461929321289, 'learning_rate': 5.418275829936537e-06, 'rewards/chosen': -5.971714973449707, 'rewards/rejected': -15.767271041870117, 'rewards/accuracies': 0.75, 'rewards/margins': 9.79555606842041, 'logps/rejected': -264.00372314453125, 'logps/chosen': -230.09046936035156, 'logits/rejected': -2.200474977493286, 'logits/chosen': -2.164147138595581, 'epoch': 0.34}\n",
      "{'loss': 0.0978, 'grad_norm': 7.358040809631348, 'learning_rate': 4.8943483704846475e-06, 'rewards/chosen': -2.901442527770996, 'rewards/rejected': -10.484598159790039, 'rewards/accuracies': 1.0, 'rewards/margins': 7.583156108856201, 'logps/rejected': -204.75868225097656, 'logps/chosen': -157.8575897216797, 'logits/rejected': -2.2743961811065674, 'logits/chosen': -2.2242965698242188, 'epoch': 0.34}\n",
      "{'loss': 0.004, 'grad_norm': 0.2918717563152313, 'learning_rate': 4.3964218465642355e-06, 'rewards/chosen': -4.909890174865723, 'rewards/rejected': -13.056760787963867, 'rewards/accuracies': 1.0, 'rewards/margins': 8.146869659423828, 'logps/rejected': -234.9774169921875, 'logps/chosen': -194.56478881835938, 'logits/rejected': -2.286561965942383, 'logits/chosen': -2.375549554824829, 'epoch': 0.34}\n",
      "{'loss': 0.0526, 'grad_norm': 5.518105983734131, 'learning_rate': 3.924632386315186e-06, 'rewards/chosen': -4.477276802062988, 'rewards/rejected': -12.263616561889648, 'rewards/accuracies': 1.0, 'rewards/margins': 7.78633975982666, 'logps/rejected': -249.2708740234375, 'logps/chosen': -202.5902557373047, 'logits/rejected': -2.316673994064331, 'logits/chosen': -2.428208827972412, 'epoch': 0.34}\n",
      "{'loss': 0.0001, 'grad_norm': 0.019807297736406326, 'learning_rate': 3.4791089722651436e-06, 'rewards/chosen': -2.4213879108428955, 'rewards/rejected': -12.526911735534668, 'rewards/accuracies': 1.0, 'rewards/margins': 10.105524063110352, 'logps/rejected': -229.63912963867188, 'logps/chosen': -169.32080078125, 'logits/rejected': -2.399710178375244, 'logits/chosen': -2.5955734252929688, 'epoch': 0.34}\n",
      "{'loss': 0.1063, 'grad_norm': 14.528711318969727, 'learning_rate': 3.059973406066963e-06, 'rewards/chosen': -3.7986109256744385, 'rewards/rejected': -11.826715469360352, 'rewards/accuracies': 1.0, 'rewards/margins': 8.028104782104492, 'logps/rejected': -235.13583374023438, 'logps/chosen': -197.1873321533203, 'logits/rejected': -2.3264803886413574, 'logits/chosen': -2.5369763374328613, 'epoch': 0.35}\n",
      "{'loss': 0.0055, 'grad_norm': 0.726046621799469, 'learning_rate': 2.667340275199426e-06, 'rewards/chosen': -2.8511815071105957, 'rewards/rejected': -12.475282669067383, 'rewards/accuracies': 1.0, 'rewards/margins': 9.624100685119629, 'logps/rejected': -261.70330810546875, 'logps/chosen': -196.34642028808594, 'logits/rejected': -2.3625035285949707, 'logits/chosen': -2.4615111351013184, 'epoch': 0.35}\n",
      "{'loss': 0.0008, 'grad_norm': 0.17621825635433197, 'learning_rate': 2.3013169216400733e-06, 'rewards/chosen': -2.6032981872558594, 'rewards/rejected': -12.978824615478516, 'rewards/accuracies': 1.0, 'rewards/margins': 10.375528335571289, 'logps/rejected': -223.51925659179688, 'logps/chosen': -162.5883331298828, 'logits/rejected': -2.3501882553100586, 'logits/chosen': -2.4832518100738525, 'epoch': 0.35}\n",
      "{'loss': 0.0002, 'grad_norm': 0.02111251838505268, 'learning_rate': 1.9620034125190644e-06, 'rewards/chosen': -4.128492832183838, 'rewards/rejected': -14.690125465393066, 'rewards/accuracies': 1.0, 'rewards/margins': 10.561634063720703, 'logps/rejected': -268.3995666503906, 'logps/chosen': -252.4617919921875, 'logits/rejected': -2.134230136871338, 'logits/chosen': -2.227280378341675, 'epoch': 0.35}\n",
      "{'loss': 0.0001, 'grad_norm': 0.013351612724363804, 'learning_rate': 1.6494925127617634e-06, 'rewards/chosen': -5.0960164070129395, 'rewards/rejected': -16.761140823364258, 'rewards/accuracies': 1.0, 'rewards/margins': 11.665122985839844, 'logps/rejected': -282.69805908203125, 'logps/chosen': -194.71864318847656, 'logits/rejected': -2.264572858810425, 'logits/chosen': -2.4025988578796387, 'epoch': 0.35}\n",
      "{'loss': 0.0012, 'grad_norm': 0.13532204926013947, 'learning_rate': 1.3638696597277679e-06, 'rewards/chosen': -5.2222490310668945, 'rewards/rejected': -12.426047325134277, 'rewards/accuracies': 1.0, 'rewards/margins': 7.203798294067383, 'logps/rejected': -230.6826629638672, 'logps/chosen': -197.60604858398438, 'logits/rejected': -2.2661983966827393, 'logits/chosen': -2.406477928161621, 'epoch': 0.35}\n",
      "{'loss': 0.0002, 'grad_norm': 0.04227868467569351, 'learning_rate': 1.1052129398531507e-06, 'rewards/chosen': -3.5502452850341797, 'rewards/rejected': -16.887678146362305, 'rewards/accuracies': 1.0, 'rewards/margins': 13.337433815002441, 'logps/rejected': -280.28631591796875, 'logps/chosen': -194.31698608398438, 'logits/rejected': -2.282363176345825, 'logits/chosen': -2.5231151580810547, 'epoch': 0.36}\n",
      "{'loss': 0.0006, 'grad_norm': 0.07755528390407562, 'learning_rate': 8.735930673024806e-07, 'rewards/chosen': -2.0738155841827393, 'rewards/rejected': -12.352070808410645, 'rewards/accuracies': 1.0, 'rewards/margins': 10.278255462646484, 'logps/rejected': -237.14559936523438, 'logps/chosen': -185.19715881347656, 'logits/rejected': -2.2522120475769043, 'logits/chosen': -2.3702480792999268, 'epoch': 0.36}\n",
      "{'loss': 0.0088, 'grad_norm': 1.3406026363372803, 'learning_rate': 6.690733646361857e-07, 'rewards/chosen': -3.617884397506714, 'rewards/rejected': -12.266833305358887, 'rewards/accuracies': 1.0, 'rewards/margins': 8.648948669433594, 'logps/rejected': -224.24072265625, 'logps/chosen': -183.042236328125, 'logits/rejected': -2.1213464736938477, 'logits/chosen': -2.2736308574676514, 'epoch': 0.36}\n",
      "{'loss': 0.0, 'grad_norm': 0.0013901941711083055, 'learning_rate': 4.917097454988584e-07, 'rewards/chosen': -1.8446764945983887, 'rewards/rejected': -14.829166412353516, 'rewards/accuracies': 1.0, 'rewards/margins': 12.984490394592285, 'logps/rejected': -250.7808837890625, 'logps/chosen': -193.99908447265625, 'logits/rejected': -2.3098995685577393, 'logits/chosen': -2.5510196685791016, 'epoch': 0.36}\n",
      "{'loss': 0.0025, 'grad_norm': 0.33396798372268677, 'learning_rate': 3.415506993330153e-07, 'rewards/chosen': -5.319533824920654, 'rewards/rejected': -16.7237491607666, 'rewards/accuracies': 1.0, 'rewards/margins': 11.404215812683105, 'logps/rejected': -269.8678283691406, 'logps/chosen': -198.27359008789062, 'logits/rejected': -2.3105692863464355, 'logits/chosen': -2.3992438316345215, 'epoch': 0.36}\n",
      "{'loss': 0.0669, 'grad_norm': 6.639224529266357, 'learning_rate': 2.1863727812254653e-07, 'rewards/chosen': -7.318767547607422, 'rewards/rejected': -10.964466094970703, 'rewards/accuracies': 1.0, 'rewards/margins': 3.6456995010375977, 'logps/rejected': -219.55352783203125, 'logps/chosen': -186.4147186279297, 'logits/rejected': -2.525160312652588, 'logits/chosen': -2.572261333465576, 'epoch': 0.37}\n",
      "{'loss': 0.0637, 'grad_norm': 9.56101131439209, 'learning_rate': 1.230030851695263e-07, 'rewards/chosen': -3.362069606781006, 'rewards/rejected': -8.064323425292969, 'rewards/accuracies': 1.0, 'rewards/margins': 4.702254295349121, 'logps/rejected': -190.17132568359375, 'logps/chosen': -158.51858520507812, 'logits/rejected': -2.4376115798950195, 'logits/chosen': -2.4495999813079834, 'epoch': 0.37}\n",
      "{'train_runtime': 4231.434, 'train_samples_per_second': 0.189, 'train_steps_per_second': 0.047, 'train_loss': 0.049025926276300424, 'epoch': 0.37}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.049025926276300424, metrics={'train_runtime': 4231.434, 'train_samples_per_second': 0.189, 'train_steps_per_second': 0.047, 'total_flos': 0.0, 'train_loss': 0.049025926276300424, 'epoch': 0.36714089031665903})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = \"experiments_dpo\"\n",
    "\n",
    "training_args = DPOConfig(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=200,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "dpo_args = {\n",
    "    \"beta\": 0.1,\n",
    "}\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    # fill the gap\n",
    "    model=model, beta=dpo_args[\"beta\"], args=training_args, tokenizer=tokenizer, train_dataset=data_dpo,\n",
    "    # Data collator is not needed for DPOTrainer as it internally manages it\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MswGlbg38NXx"
   },
   "source": [
    "## Test the model after DPO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "NiEYtq-yJ1aw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\red-y\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<system> You are a helpful assistant <human>: Can you taste this dish and tell me if it needs more spices?  \n",
      "<assistant>:  I am a computational linguistic system, and based upon my understanding of the provided description of the dish 'Tasting the Dish', I am able to provide some insights into its potential for further seasoning or enhancement through the use of spices.  While I cannot directly taste the dish, I can provide general observations regarding the potential for further seasoning based on the available information.  The specific details of the dish, such as its ingredients, flavors, and textures, may influence the overall potential for further seasoning.  However, based on my understanding of the available information, I would suggest that further seasoning may be beneficial in enhancing the flavor and overall experience of the dish.  This may include the use of additional spices, herbs, or other flavor enhancers that can complement the existing flavors.  Ultimately, the final decision regarding further seasoning will depend on the individual preferences and the specific needs of the diner.\n",
      "CPU times: total: 12 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda:0\"\n",
    "\n",
    "encoding = tokenizer(prompt_2, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "-NfI1G1bJ1aw"
   },
   "outputs": [],
   "source": [
    "def generate_response(question: str) -> str:\n",
    "    prompt = f\"<human>: {question}  \\n<assistant>: \"# construct same promt as before\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=encoding.input_ids,\n",
    "            attention_mask=encoding.attention_mask,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    assistant_start = \"<assistant>:\"\n",
    "    response_start = response.find(assistant_start)\n",
    "    return response[response_start + len(assistant_start) :].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_z0Nl1sJ1ax",
    "outputId": "397916fc-c59b-4e99-d23c-6b501c9f9de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Do people dream in color or black and white? \n",
      "\n",
      "Many people do, and it is a topic of debate and interpretation within the field of psychology and philosophy of mind.  Some argue that color and black and white are distinct and complementary aspects of the human experience, while others emphasize the interplay of color and black and white as a continuum or a dichotomy.  Some argue that color and black and white are complementary aspects of the human experience, with different aspects of the world and the mind being colored by different aspects of the spectrum.  Others argue that color and black and white are dichotomous, with different aspects of the mind and the world being colored by different aspects of the spectrum.  Ultimately, the debate remains open, and the interpretation of color and black and white as complementary or dichotomous depends on individual perspectives and experiences.\n",
      "\n",
      "\n",
      "\n",
      "- Explain the concept of economic policies in simple terms \n",
      "\n",
      "Economic policies, also known as economic management, are a set of measures or guidelines developed by a government or other economic institution to guide and coordinate the economic activities of a nation, a region, or an economy.  Economic policies are designed to achieve a balance between economic growth, stability, and social welfare, while taking into account the economic, political, and social factors that influence the economy.  The primary objectives of economic policies are to promote economic growth, reduce economic volatility, foster economic stability, and ensure a sustainable economic framework.  These policies may include fiscal, monetary, and fiscal, trade, exchange rate, and other economic policies, as well as fiscal, monetary, and fiscal policies.  The goal of economic policies is to create a conducive environment for economic growth, stability, and sustainable development.  <br><br> <div> <ul> <li>  <strong> 1.  Fiscal policy:  This policy aims to reduce the budget deficit or surplus, balance\n",
      "\n",
      "\n",
      "\n",
      "- Explain the effects of globalization on the environment. \n",
      "\n",
      "Globalization, the process of international and intergovernmental interactions, trade, investment, finance, technology, and culture that occurs as a result of the interconnectedness of the world economy, has had a significant impact on the environment.  The globalization of the economy has led to increased trade, investment, and the movement of goods, services, and capital across borders, which has exposed businesses, consumers, and society to a wider range of environmental issues and opportunities.  This has also raised awareness and concerns about the impact of globalization on the environment, including issues such as climate change, air and water pollution, waste management, and the depletion of natural resources.  However, globalization also presents opportunities for businesses and organizations to adopt sustainable practices and engage in responsible business practices.  This includes the use of environmentally friendly products, the implementation of green initiatives, and the promotion of sustainable development.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Do people dream in color or black and white?\"\n",
    "print('-', prompt,'\\n')\n",
    "print(generate_response(prompt))\n",
    "\n",
    "prompt = \"Explain the concept of economic policies in simple terms\"\n",
    "print('\\n\\n\\n-', prompt, '\\n')\n",
    "print(generate_response(prompt))\n",
    "\n",
    "\n",
    "prompt = \"Explain the effects of globalization on the environment.\" \n",
    "print('\\n\\n\\n-', prompt, '\\n')\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbFILfmBTh4R"
   },
   "source": [
    "Is the response improved after DPO?\n",
    "\n",
    "Yes, the response has improved because we trained it in a more targeted manner using DPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "u3CB1PUGTgyy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  What equipment do I need for rock climbing?  \n",
      "\n",
      "For rock climbing, there are a variety of equipment that can be useful for different types of rock climbing, including climbing equipment such as ropes, harnesses, helmets, gloves, chalk, chalk pads, and protection.  Some of the most common equipment used in rock climbing include ropes, harnesses, helmets, chalk, chalk pads, and protection.  The specific equipment needed will depend on the type of rock climbing, the intended use, and the individual's preferences and abilities.  However, a basic set of equipment should include a harness, a helmet, chalk, chalk pads, and protection.  Additionally, climbers may want to consider additional equipment such as ropes, carabiners, quickdraws, and other pieces of equipment specific to their intended use.\n"
     ]
    }
   ],
   "source": [
    "prompt = \" What equipment do I need for rock climbing? \"\n",
    "print('-', prompt,'\\n')\n",
    "print(generate_response(prompt))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "069c68c472424e88b5c05ec13045c0ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23954459f42b49e0bc6469f5f98ef452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ba953554175441a897015b9f3b20a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e292bbcb5df405b8483d6e7fb66df9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40596f9a20e7462b8dcb6384b1778a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46a11e8615c94331aa76c82752da6451": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "493370fa54da4a5daae5de48e7e0d716": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_069c68c472424e88b5c05ec13045c0ad",
      "placeholder": "​",
      "style": "IPY_MODEL_2ba953554175441a897015b9f3b20a50",
      "value": " 2179/2179 [00:02&lt;00:00, 926.74 examples/s]"
     }
    },
    "529bbebfb8b84e799c412f055b68dac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed194155af9441378d6a5b07b9ed8866",
       "IPY_MODEL_ab893884646c4dca9374932b6a318f2d",
       "IPY_MODEL_493370fa54da4a5daae5de48e7e0d716"
      ],
      "layout": "IPY_MODEL_db4e5c91141a40209fc814e29432fcca"
     }
    },
    "ab893884646c4dca9374932b6a318f2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e292bbcb5df405b8483d6e7fb66df9e",
      "max": 2179,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40596f9a20e7462b8dcb6384b1778a25",
      "value": 2179
     }
    },
    "db4e5c91141a40209fc814e29432fcca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed194155af9441378d6a5b07b9ed8866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46a11e8615c94331aa76c82752da6451",
      "placeholder": "​",
      "style": "IPY_MODEL_23954459f42b49e0bc6469f5f98ef452",
      "value": "Tokenizing train dataset: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
